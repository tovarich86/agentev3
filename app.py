# -*- coding: utf-8 -*-
"""
AGENTE DE CONSULTA COM L√ìGICA ORIGINAL RESTAURADA (V6)
Aplica√ß√£o web para an√°lise de planos de incentivo de longo prazo.

Esta vers√£o restaura completamente a robustez e a intelig√™ncia de
orquestra√ß√£o do agente original, aplicando-as √† nova e eficiente
estrutura de dados V7.
"""

import streamlit as st
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import os
import re
import pandas as pd
import logging
import unicodedata
import requests

# --- CONFIGURA√á√ïES GERAIS ---
BASE_PATH = 'dados'

# Caminhos para os novos artefactos V7
FAISS_INDEX_PATH = os.path.join(BASE_PATH, 'faiss_index_contextual_v7.bin')
CHUNKS_MAP_PATH = os.path.join(BASE_PATH, 'chunks_com_metadata_contextual_v7.json')
CONSOLIDATED_TABLE_PATH = os.path.join(BASE_PATH, 'tabela_consolidada_v7.csv')

MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
TOP_K_SEARCH = 25

# Configura√ß√µes da API do Gemini
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-1.5-flash-latest"

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- DICION√ÅRIOS DE CONHECIMENTO ---
TERMOS_TECNICOS_LTIP = {
    "A√ß√µes Restritas": ["Restricted Shares", "Plano de A√ß√µes Restritas", "Outorga de A√ß√µes", "a√ß√µes restritas", "RSU", "Restricted Stock Units"],
    "Op√ß√µes de Compra de A√ß√µes": ["Stock Options", "ESOP", "Plano de Op√ß√£o de Compra", "Outorga de Op√ß√µes", "op√ß√µes", "Plano de Op√ß√£o", "Plano de Op√ß√µes", "SOP"],
    "A√ß√µes Fantasmas": ["Phantom Shares", "A√ß√µes Virtuais"],
    "Op√ß√µes Fantasmas (SAR)": ["Phantom Options", "SAR", "Share Appreciation Rights", "Direito √† Valoriza√ß√£o de A√ß√µes"],
    "Planos com Condi√ß√£o de Performance": ["Performance Shares", "Performance Units", "PSU", "Plano de Desempenho", "Metas de Performance", "performance", "desempenho"],
    "Plano de Compra de A√ß√µes (ESPP)": ["Plano de Compra de A√ß√µes", "Employee Stock Purchase Plan", "ESPP", "A√ß√µes com Desconto"],
    "B√¥nus Diferido": ["Staying Bonus", "Retention Bonus", "B√¥nus de Perman√™ncia", "B√¥nus de Reten√ß√£o", "b√¥nus", "Deferred Bonus"],
    "Matching": ["Matching", "Contrapartida", "Co-investimento", "Plano de Matching", "investimento"],
    "Outorga": ["Outorga", "Concess√£o", "Grant", "Grant Date", "Data da Outorga", "Aprova√ß√£o"],
    "Vesting": ["Vesting", "Per√≠odo de Car√™ncia", "Condi√ß√µes de Car√™ncia", "Aquisi√ß√£o de Direitos", "car√™ncia", "cronograma de vesting"],
    "Antecipa√ß√£o de Vesting": ["Vesting Acelerado", "Accelerated Vesting", "Cl√°usula de Acelera√ß√£o", "antecipa√ß√£o de car√™ncia", "antecipa√ß√£o do vesting", "antecipa√ß√£o"],
    "Tranche / Lote": ["Tranche", "Lote", "Parcela do Vesting"],
    "Cliff": ["Cliff Period", "Per√≠odo de Cliff", "Car√™ncia Inicial"],
    "Pre√ßo": ["Pre√ßo", "Pre√ßo de Exerc√≠cio", "Strike", "Strike Price"],
    "Ciclo de Vida do Exerc√≠cio": ["Exerc√≠cio", "Per√≠odo de Exerc√≠cio", "pagamento", "liquida√ß√£o", "vencimento", "expira√ß√£o", "forma de liquida√ß√£o"],
    "Lockup": ["Lockup", "Per√≠odo de Lockup", "Restri√ß√£o de Venda", "per√≠odo de restri√ß√£o"],
    "Governan√ßa e Documentos": ["Regulamento", "Regulamento do Plano", "Contrato de Ades√£o", "Termo de Outorga", "Comit√™ de Remunera√ß√£o", "Comit√™ de Pessoas", "Delibera√ß√£o"],
    "Malus e Clawback": ["Malus", "Clawback", "Redu√ß√£o", "Devolu√ß√£o", "Cl√°usula de Recupera√ß√£o", "Forfeiture", "Cancelamento", "Perda do Direito"],
    "Estrutura do Plano/Programa": ["Plano", "Planos", "Programa", "Programas", "termos e condi√ß√µes gerais"],
    "Dilui√ß√£o": ["Dilui√ß√£o", "Dilution", "Capital Social"],
    "Eleg√≠veis": ["Participantes", "Benefici√°rios", "Eleg√≠veis", "Empregados", "Administradores", "Executivos", "Colaboradores", "Conselheiros"],
    "Condi√ß√£o de Sa√≠da": ["Desligamento", "Sa√≠da", "T√©rmino do Contrato", "Rescis√£o", "Demiss√£o", "Good Leaver", "Bad Leaver"],
    "Tratamento em Casos Especiais": ["Aposentadoria", "Morte", "Invalidez", "Reforma", "Afastamento"],
    "Indicadores": ["TSR", "Total Shareholder Return", "Retorno Total ao Acionista", "CDI", "IPCA", "Selic", "ROIC", "EBITDA", "LAIR", "Lucro", "CAGR", "Metas ESG", "Receita L√≠quida"],
    "Eventos Corporativos": ["IPO", "grupamento", "desdobramento", "cis√£o", "fus√£o", "incorpora√ß√£o", "bonifica√ß√µes", "bonifica√ß√£o"],
    "Mudan√ßa de Controle": ["Mudan√ßa de Controle", "Change of Control", "Evento de Liquidez"],
    "Dividendos": ["Dividendos", "Dividendo", "JCP", "Juros sobre capital pr√≥prio", "Tratamento de Dividendos", "dividend equivalent", "proventos"],
    "Encargos": ["Encargos", "Impostos", "Tributa√ß√£o", "Natureza Mercantil", "Natureza Remunerat√≥ria", "INSS", "IRRF"],
    "Contabilidade e Normas": ["IFRS 2", "CPC 10", "Valor Justo", "Fair Value", "Black-Scholes", "Despesa Cont√°bil", "Volatilidade"]
}
AVAILABLE_TOPICS = list(TERMOS_TECNICOS_LTIP.keys())

# --- CARREGAMENTO DE DADOS ---

@st.cache_resource
def load_all_artifacts():
    artifacts = {"model": None, "index": None, "chunks_dict": None, "consolidated_df": None, "company_catalog": None}
    try:
        logger.info("A carregar artefactos...")
        artifacts["model"] = SentenceTransformer(MODEL_NAME)
        artifacts["index"] = faiss.read_index(FAISS_INDEX_PATH)
        with open(CHUNKS_MAP_PATH, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)
        artifacts["chunks_dict"] = {chunk['id']: chunk for chunk in chunks_data}
        artifacts["consolidated_df"] = pd.read_csv(CONSOLIDATED_TABLE_PATH)
        try:
            from catalog_data import company_catalog_rich
            artifacts["company_catalog"] = company_catalog_rich
        except ImportError:
            logger.warning("`catalog_data.py` n√£o encontrado.")
        logger.info("‚úÖ Artefactos carregados com sucesso.")
        return artifacts
    except Exception as e:
        st.error(f"ERRO CR√çTICO AO CARREGAR ARTEFACTOS: {e}")
        return artifacts

# --- L√ìGICA DE ORQUESTRA√á√ÉO E AN√ÅLISE ---

def get_llm_json_response(prompt):
    if not GEMINI_API_KEY: return None
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"response_mime_type": "application/json"}}
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=90)
        response.raise_for_status()
        text_response = response.json()['candidates'][0]['content']['parts'][0]['text']
        return json.loads(text_response)
    except Exception as e:
        logger.error(f"Falha ao obter resposta JSON do LLM: {e}")
        return None

def create_analysis_plan(query, company_catalog, all_known_companies):
    company_prompt = f'Dada a lista de empresas conhecidas: {json.dumps(all_known_companies)}. Analise a pergunta do utilizador: "{query}". Identifique TODAS as empresas da lista que s√£o mencionadas. Retorne APENAS uma lista JSON com os nomes can√≥nicos. Exemplo: ["Empresa A", "Empresa B"]'
    mentioned_companies = get_llm_json_response(company_prompt)

    if not mentioned_companies:
        return None

    topic_prompt = f'Voc√™ √© um consultor de ILP. Identifique os T√ìPICOS CENTRAIS da pergunta: "{query}". Retorne APENAS uma lista JSON com os t√≥picos mais relevantes da seguinte lista: {json.dumps(AVAILABLE_TOPICS)}. Se for gen√©rica, use ["Estrutura do Plano/Programa", "Vesting", "Eleg√≠veis"].'
    topics = get_llm_json_response(topic_prompt) or ["Estrutura do Plano/Programa", "Vesting", "Eleg√≠veis"]

    return {"empresas": mentioned_companies, "topicos": topics, "tipo_analise": "comparativa" if len(mentioned_companies) > 1 else "unica"}

def execute_rag_analysis(plan, artifacts):
    model, index, chunks_dict = artifacts["model"], artifacts["index"], artifacts["chunks_dict"]
    all_context, all_sources = "", set()

    for company in plan['empresas']:
        specific_query = f"An√°lise sobre {', '.join(plan['topicos'])} para a empresa {company}"
        logger.info(f"A criar busca espec√≠fica: '{specific_query}'")
        query_vector = model.encode([specific_query], normalize_embeddings=True).astype('float32')
        distances, ids = index.search(query_vector, TOP_K_SEARCH)
        
        company_context, company_sources = "", set()
        if ids.size > 0:
            for chunk_id in ids[0]:
                if chunk_id != -1 and (chunk_info := chunks_dict.get(chunk_id)) and company.lower() in chunk_info['metadata']['empresa'].lower():
                    metadata = chunk_info['metadata']
                    company_context += f"--- Contexto (Fonte: {metadata['arquivo_origem']}) ---\nSec√ß√£o: {metadata['section_title']}\nConte√∫do: {chunk_info['content']}\n\n"
                    company_sources.add(chunk_info['source'])
        
        if company_context:
            all_context += f"--- AN√ÅLISE PARA {company.upper()} ---\n\n{company_context}"
            all_sources.update(company_sources)

    return all_context, all_sources

def get_final_answer(prompt):
    if not GEMINI_API_KEY: return "ERRO: Chave de API n√£o configurada."
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 0.2, "maxOutputTokens": 8192}}
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        logger.error(f"ERRO ao gerar resposta final com LLM: {e}")
        return f"ERRO ao gerar resposta final."

def handle_aggregate_query(query, df):
    st.info("Detectada uma pergunta agregada. A analisar a tabela consolidada...")
    query_lower = query.lower()
    try:
        match = re.search(r'(?:com|t√™m|possuem|oferecem)\s+(.+)', query_lower)
        if not match:
            st.warning("N√£o consegui entender qual caracter√≠stica procura. Tente 'Quais empresas t√™m A√ß√µes Restritas?'.")
            return
        target_feature = match.group(1).replace('?', '').strip()
        results_df = df[df['nomes_planos'].str.contains(target_feature, case=False, na=False)]
        if results_df.empty:
            st.warning(f"Nenhuma empresa encontrada com planos que mencionam '{target_feature}'.")
        else:
            empresas = sorted(results_df['empresa'].unique())
            st.success(f"‚úÖ **{len(empresas)} empresa(s)** encontrada(s) com planos que mencionam '{target_feature}':")
            st.dataframe(pd.DataFrame(empresas, columns=["Empresa"]), use_container_width=True, hide_index=True)
    except Exception as e:
        logger.error(f"Erro na busca agregada: {e}")
        st.error("Ocorreu um erro ao analisar a sua pergunta.")

# --- INTERFACE STREAMLIT ---
def main():
    st.set_page_config(page_title="Agente de An√°lise LTIP (V6)", page_icon="üîç", layout="wide")
    st.title("ü§ñ Agente de An√°lise de Planos de Incentivo (V6)")
    st.markdown("---")

    artifacts = load_all_artifacts()
    if not artifacts["model"]: return

    with st.sidebar:
        st.header("üìä Informa√ß√µes do Sistema")
        if artifacts["consolidated_df"] is not None:
            st.metric("Documentos na Base", len(artifacts["consolidated_df"]['caminho_completo'].unique()))
        if artifacts["chunks_dict"] is not None:
            st.metric("Chunks Indexados", len(artifacts["chunks_dict"]))
        st.success("‚úÖ Sistema pronto para an√°lise")

    st.header("üí¨ Fa√ßa a sua pergunta")
    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Como √© o plano de vesting da Vale? ou Compare o tratamento de dividendos da Petrobras com a Gerdau.")

    if st.button("üîç Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
            return

        # --- ROTEADOR DE INTEN√á√ÉO ---
        is_aggregate = any(keyword in user_query.lower() for keyword in ["quais", "quantas", "liste"])
        
        if is_aggregate:
            handle_aggregate_query(user_query, artifacts["consolidated_df"])
        else:
            with st.status("1Ô∏è‚É£ A criar plano de an√°lise...", expanded=True) as status:
                known_companies = artifacts["consolidated_df"]['empresa'].unique().tolist()
                plan = create_analysis_plan(user_query, artifacts["company_catalog"], known_companies)
                if not plan:
                    st.error("‚ùå Nenhuma empresa conhecida foi identificada na sua pergunta.")
                    status.update(label="Falha ao criar plano.", state="error")
                    return
                st.write(f"**Tipo de An√°lise:** {plan['tipo_analise'].title()}")
                st.write(f"**Empresa(s):** {', '.join(plan['empresas'])}")
                st.write(f"**T√≥picos Identificados:** {', '.join(plan['topicos'])}")
                status.update(label="Plano de an√°lise criado!", state="complete")

            with st.spinner("2Ô∏è‚É£ A executar a busca e a recolher o contexto..."):
                context, sources = execute_rag_analysis(plan, artifacts)
            
            st.markdown("---")
            st.subheader("üìã Resultado da An√°lise")

            if not context:
                st.warning("N√£o foram encontrados contextos relevantes para responder √† pergunta.")
                return
                
            with st.spinner("3Ô∏è‚É£ A gerar a resposta final com o Gemini..."):
                prompt = f"""Voc√™ √© um consultor especialista em planos de incentivo de longo prazo (ILP).
                Sua tarefa √© responder √† pergunta do utilizador com base no contexto fornecido.
                Se a pergunta for uma compara√ß√£o, crie um relat√≥rio comparativo bem estruturado.
                Se a pergunta for sobre uma √∫nica empresa, forne√ßa uma an√°lise detalhada.
                Seja profissional e baseie-se estritamente nos dados. Se a informa√ß√£o n√£o estiver no contexto, afirme isso claramente.

                PERGUNTA ORIGINAL DO UTILIZADOR: "{user_query}"

                CONTEXTO COLETADO DOS DOCUMENTOS:
                {context}

                RELAT√ìRIO ANAL√çTICO FINAL:
                """
                final_answer = get_final_answer(prompt)
                st.markdown(final_answer)

            if sources:
                with st.expander(f"üìö Documentos consultados ({len(sources)})", expanded=False):
                    for source in sorted(list(sources)):
                        st.write(f"- {os.path.basename(source)}")

if __name__ == "__main__":
    main()
