# -*- coding: utf-8 -*-
"""
AGENTE DE AN√ÅLISE LTIP - VERS√ÉO FINAL E FUNCIONAL
"""

# --- 1. Importa√ß√µes e Configura√ß√µes ---
import streamlit as st
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import requests
import glob
import os
import re
import unicodedata
import logging
import pandas as pd
from pathlib import Path

try:
    from knowledge_base import DICIONARIO_UNIFICADO_HIERARQUICO
except ImportError:
    st.error("ERRO CR√çTICO: Crie o arquivo 'knowledge_base.py' e cole o 'DICIONARIO_UNIFICADO_HIERARQUICO' nele.")
    st.stop()

# Configura√ß√µes Gerais
MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
TOP_K_SEARCH = 7
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-1.5-flash-latest" # Usando o modelo mais recente e capaz
DADOS_PATH = Path("dados")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# --- 2. Carregamento de Dados e Fun√ß√µes Auxiliares ---

@st.cache_resource
def load_all_artifacts():
    DADOS_PATH.mkdir(exist_ok=True)
    ARQUIVOS_REMOTOS = {
        "item_8_4_chunks_map_final.json": "https://github.com/tovarich86/agentev2/releases/download/V1.0-data/item_8_4_chunks_map_final.json",
        "item_8_4_faiss_index_final.bin": "https://github.com/tovarich86/agentev2/releases/download/V1.0-data/item_8_4_faiss_index_final.bin",
        "outros_documentos_chunks_map_final.json": "https://github.com/tovarich86/agentev2/releases/download/V1.0-data/outros_documentos_chunks_map_final.json",
        "outros_documentos_faiss_index_final.bin": "https://github.com/tovarich86/agentev2/releases/download/V1.0-data/outros_documentos_faiss_index_final.bin",
        "resumo_fatos_e_topicos_final_enriquecido.json": "https://github.com/tovarich86/agentev2/releases/download/V1.0-data/resumo_fatos_e_topicos_final_enriquecido.json"
    }
    for nome_arquivo, url in ARQUIVOS_REMOTOS.items():
        caminho_arquivo = DADOS_PATH / nome_arquivo
        if not caminho_arquivo.exists():
            with st.spinner(f"Baixando artefato: {nome_arquivo}..."):
                try:
                    r = requests.get(url, stream=True)
                    r.raise_for_status()
                    with open(caminho_arquivo, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192): f.write(chunk)
                except requests.exceptions.RequestException as e:
                    st.error(f"Falha ao baixar {nome_arquivo}: {e}"); st.stop()
    
    _model = SentenceTransformer(MODEL_NAME)
    artifacts = {}
    index_files = glob.glob(str(DADOS_PATH / '*_faiss_index_final.bin'))
    for index_file_path in index_files:
        category = Path(index_file_path).stem.replace('_faiss_index_final', '')
        chunks_file_path = DADOS_PATH / f"{category}_chunks_map_final.json"
        try:
            index = faiss.read_index(index_file_path)
            with open(chunks_file_path, 'r', encoding='utf-8') as f:
                chunk_data = json.load(f)
            artifacts[category] = {'index': index, 'chunks': chunk_data}
        except Exception as e:
            logger.error(f"Erro ao carregar '{category}': {e}"); continue
    
    summary_data = None
    summary_file_path = DADOS_PATH / 'resumo_fatos_e_topicos_final_enriquecido.json'
    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
    except FileNotFoundError:
        logger.error(f"Arquivo de resumo '{summary_file_path}' n√£o encontrado.")
            
    return _model, artifacts, summary_data

@st.cache_data
def criar_mapa_de_alias():
    alias_to_canonical = {}
    for section, topics in DICIONARIO_UNIFICADO_HIERARQUICO.items():
        for canonical_name, aliases in topics.items():
            alias_to_canonical[canonical_name.lower()] = canonical_name
            for alias in aliases:
                alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical


# --- 3. Fun√ß√µes de L√≥gica de Neg√≥cio (Manipuladores de Query) ---

def handle_analytical_query(query: str, summary_data: dict):
    query_lower = query.lower()
    op_keywords = {'avg': ['medio', 'm√©dia', 't√≠pico'], 'min': ['menor', 'm√≠nimo'], 'max': ['maior', 'm√°ximo']}
    fact_keywords = {
        'periodo_vesting': ['vesting', 'per√≠odo de car√™ncia'], 'periodo_lockup': ['lockup', 'lock-up'],
        'desconto_strike_price': ['desconto', 'des√°gio'], 'prazo_exercicio': ['prazo de exerc√≠cio']
    }
    operation, target_fact_key = None, None
    for op, keywords in op_keywords.items():
        if any(kw in query_lower for kw in keywords): operation = op; break
    for fact_key, keywords in fact_keywords.items():
        if any(kw in query_lower for kw in keywords): target_fact_key = fact_key; break
    if not operation or not target_fact_key: return False
    
    st.info(f"Analisando: **{operation.upper()}** para o fato **'{target_fact_key}'**...")
    valores, unidade = [], ''
    for data in summary_data.values():
        if target_fact_key in data.get("fatos_extraidos", {}):
            fact_data = data["fatos_extraidos"][target_fact_key]
            valor = fact_data.get('valor_numerico') or fact_data.get('valor')
            if isinstance(valor, (int, float)):
                valores.append(valor)
                if not unidade and 'unidade' in fact_data: unidade = fact_data['unidade']
    if not valores:
        st.warning(f"N√£o encontrei dados num√©ricos para '{target_fact_key}' para calcular."); return True

    resultado, label_metrica = 0, ""
    if operation == 'avg': resultado, label_metrica = np.mean(valores), f"M√©dia de {target_fact_key.replace('_', ' ')}"
    elif operation == 'min': resultado, label_metrica = np.min(valores), f"M√≠nimo de {target_fact_key.replace('_', ' ')}"
    elif operation == 'max': resultado, label_metrica = np.max(valores), f"M√°ximo de {target_fact_key.replace('_', ' ')}"
    
    valor_formatado = f"{resultado:.1%}" if target_fact_key == 'desconto_strike_price' else f"{resultado:.1f} {unidade}".strip()
    st.metric(label=label_metrica.title(), value=valor_formatado)
    st.caption(f"C√°lculo baseado em {len(valores)} empresas com dados para este fato.")
    return True

def handle_aggregate_query(query: str, summary_data: dict, alias_map: dict):
    query_lower = query.lower()
    query_keywords = set()
    sorted_aliases = sorted(alias_map.keys(), key=len, reverse=True)
    temp_query = query_lower
    for alias in sorted_aliases:
        if re.search(r'\b' + re.escape(alias.lower()) + r'\b', temp_query):
            query_keywords.add(alias.lower()); temp_query = temp_query.replace(alias.lower(), "")
    if not query_keywords: st.warning("N√£o identifiquei um termo t√©cnico na sua pergunta."); return
    st.info(f"Termos para busca: **{', '.join(sorted(list(query_keywords)))}**")
    empresas_encontradas = []
    for empresa, data in summary_data.items():
        company_terms = set()
        for topics in data.get("topicos_encontrados", {}).values():
            for topic, aliases in topics.items():
                company_terms.add(topic.lower()); company_terms.update([a.lower() for a in aliases])
        if query_keywords.issubset(company_terms): empresas_encontradas.append(empresa)
    if not empresas_encontradas: st.warning(f"Nenhuma empresa encontrada com: `{', '.join(query_keywords)}`."); return
    st.success(f"‚úÖ **{len(empresas_encontradas)} empresa(s)** encontrada(s).")
    df = pd.DataFrame(sorted(empresas_encontradas), columns=["Empresa"])
    st.dataframe(df, use_container_width=True, hide_index=True)

def handle_direct_fact_query(query: str, summary_data: dict, alias_map: dict, company_catalog: list):
    query_lower, empresa_encontrada, fato_encontrado_alias = query.lower(), None, None
    for company_data in company_catalog:
        for alias in company_data.get("aliases", []):
            if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                empresa_encontrada = company_data["canonical_name"].upper(); break
        if empresa_encontrada: break
    for alias in sorted(alias_map.keys(), key=len, reverse=True):
        if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
            fato_encontrado_alias = alias; break
    if not empresa_encontrada or not fato_encontrado_alias: return False
    empresa_data = summary_data.get(empresa_encontrada, {})
    st.subheader(f"Fato Direto para: {empresa_encontrada}")
    fato_encontrado = False
    for fact_key, fact_value in empresa_data.get("fatos_extraidos", {}).items():
        if fato_encontrado_alias in fact_key.lower():
            valor, unidade = fact_value.get('valor', ''), fact_value.get('unidade', '')
            st.metric(label=f"Fato: {fact_key.replace('_', ' ').title()}", value=f"{valor} {unidade}".strip())
            fato_encontrado = True; break
    if not fato_encontrado: st.info(f"O t√≥pico '{fato_encontrado_alias}' foi mencionado, mas um fato estruturado n√£o foi extra√≠do.")
    return True

# --- FUN√á√ïES DO PIPELINE RAG (VERS√ÉO FINAL E FUNCIONAL) ---

# --- FUN√á√ïES AUXILIARES RESTAURADAS E ADAPTADAS ---

def expand_search_terms(base_term: str, alias_map: dict, knowledge_base: dict) -> list[str]:
    """
    (ADAPTADO DO C√ìDIGO ANTIGO) Expande um termo de busca para incluir sin√¥nimos.
    Funciona com a nova estrutura do DICIONARIO_UNIFICADO_HIERARQUICO.
    """
    canonical_name = alias_map.get(base_term.lower())
    if not canonical_name:
        return [base_term]

    expanded_terms = set([canonical_name])
    for section, topics in knowledge_base.items():
        if canonical_name in topics:
            expanded_terms.update(topics[canonical_name])
            expanded_terms.add(canonical_name) # Garante que o nome can√¥nico est√° l√°
            break
            
    return list(expanded_terms)

def search_by_tags(artifacts: dict, company_name: str, target_tags: list[str]) -> list[dict]:
    """
    (ADAPTADO DO C√ìDIGO ANTIGO) Busca por chunks que contenham tags de t√≥picos.
    Agora usa o metadado 'company_name' em vez de buscar no nome do arquivo, o que √© mais robusto.
    """
    results = []
    # Converte tags para um formato mais f√°cil de buscar (ex: ignora case)
    target_tags_lower = {tag.lower() for tag in target_tags}

    for category, artifact_data in artifacts.items():
        chunk_data = artifact_data.get('chunks', {})
        for i, mapping in enumerate(chunk_data.get('map', [])):
            # L√ìGICA ADAPTADA: Verifica o metadado da empresa
            if company_name.upper() == mapping.get("company_name", "").upper():
                chunk_text = chunk_data.get("chunks", [])[i]
                # Verifica se alguma das tags est√° no texto do chunk
                # Isso √© uma simplifica√ß√£o, a busca por regex do c√≥digo antigo era mais espec√≠fica
                # para "T√≥picos:" ou "Item 8.4 - Subitens:". Podemos adicionar se necess√°rio.
                # Por agora, vamos buscar a men√ß√£o da tag no texto.
                for tag in target_tags_lower:
                    if re.search(r'\b' + re.escape(tag) + r'\b', chunk_text, re.IGNORECASE):
                        results.append({
                            'text': chunk_text,
                            'source_url': mapping.get("source_url", "Fonte Desconhecida"),
                            'tag_found': tag
                        })
                        break # P√°ra no primeiro tag encontrado para este chunk
    return results

# --- FUN√á√ïES DO PIPELINE RAG (VERS√ÉO H√çBRIDA E DIN√ÇMICA) ---

def create_dynamic_rag_plan(query: str, company_catalog: list, alias_map: dict, knowledge_base: dict) -> dict | None:
    """
    (H√çBRIDO E DIN√ÇMICO - V3) Cria um plano de busca, combinando regras locais com fallback para LLM.
    """
    query_lower = query.lower()
    plan = {"empresas": [], "topicos": []}
    
    # --- ETAPA 1: TENTATIVA DE PLANEJAMENTO LOCAL (R√ÅPIDO E BARATO) ---
    # Identifica empresas usando o cat√°logo
    for company_data in company_catalog:
        for alias in company_data.get("aliases", []):
            if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                plan["empresas"].append(company_data["canonical_name"])
                break
    plan["empresas"] = sorted(list(set(plan["empresas"])))

    # Identifica t√≥picos usando o mapa de alias
    for alias, canonical_name in alias_map.items():
        if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
            plan["topicos"].append(canonical_name)
    plan["topicos"] = sorted(list(set(plan["topicos"])))

    # Se n√£o encontrou empresa, o plano √© inv√°lido
    if not plan["empresas"]:
        return None

    # Se encontrou t√≥picos localmente, o plano est√° pronto!
    if plan["topicos"]:
        logger.info(f"Plano RAG criado com regras locais: Empresas={plan['empresas']}, T√≥picos={plan['topicos']}")
        return plan

    # --- ETAPA 2: FALLBACK PARA LLM (SE NENHUM T√ìPICO FOI ENCONTRADO) ---
    logger.warning(f"Nenhum t√≥pico local encontrado para a query. Acionando LLM para planejamento.")
    st.info("Nenhum termo t√©cnico conhecido foi encontrado. Usando IA para interpretar os t√≥picos da sua pergunta...")

    if not GEMINI_API_KEY:
        st.error("Chave da API Gemini n√£o configurada para o planejamento din√¢mico.")
        # Fallback para um plano gen√©rico se a API n√£o estiver dispon√≠vel
        plan["topicos"] = ["informa√ß√µes gerais do plano de incentivo"]
        return plan

    # Extrai todos os nomes de t√≥picos can√¥nicos da base de conhecimento
    available_topics = list(knowledge_base.keys())
    for section_topics in knowledge_base.values():
        available_topics.extend(section_topics.keys())
    
    prompt = f"""Voc√™ √© um assistente especialista em planos de incentivo. Analise a pergunta do usu√°rio e identifique os t√≥picos centrais que devem ser pesquisados.
    
    **Pergunta do Usu√°rio:** "{query}"

    **T√≥picos Dispon√≠veis para Escolha:** {json.dumps(list(set(available_topics)), ensure_ascii=False)}

    **Sua Tarefa:**
    Retorne uma lista JSON com os nomes EXATOS dos t√≥picos mais relevantes da lista acima que correspondem √† pergunta do usu√°rio.
    Se a pergunta for gen√©rica sobre um plano (ex: "como √© o plano da vale?"), retorne uma lista com t√≥picos essenciais como ["Estrutura do Plano/Programa", "Vesting", "Governan√ßa e Documentos"].
    O formato da sua resposta deve ser APENAS a lista JSON. Exemplo: ["Vesting", "Lockup", "Dividendos"]
    """
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=90)
        response.raise_for_status()
        text_response = response.json()['candidates'][0]['content']['parts'][0]['text']
        
        # Tenta extrair a lista JSON da resposta
        json_match = re.search(r'\[.*\]', text_response, re.DOTALL)
        if json_match:
            plan["topicos"] = json.loads(json_match.group(0))
            logger.info(f"Plano RAG criado via LLM: Empresas={plan['empresas']}, T√≥picos={plan['topicos']}")
        else:
            raise ValueError("Resposta do LLM n√£o continha um JSON v√°lido.")
            
    except (requests.exceptions.RequestException, KeyError, IndexError, ValueError) as e:
        logger.error(f"Falha ao usar LLM para planejamento: {e}. Usando t√≥picos de fallback.")
        st.warning("Falha na interpreta√ß√£o por IA. Usando uma busca gen√©rica.")
        plan["topicos"] = ["informa√ß√µes gerais do plano de incentivo", "Estrutura do Plano/Programa"]
        
    return plan


def execute_hybrid_rag_plan(plan: dict, artifacts: dict, model, alias_map: dict, knowledge_base: dict) -> tuple[str, set]:
    """
    (BUSCA H√çBRIDA) Executa a busca em duas etapas: tags (precis√£o) e sem√¢ntica (cobertura).
    """
    full_context, sources, unique_chunks = "", set(), set()
    
    with st.spinner("Executando busca de alta precis√£o por tags..."):
        # Expande todos os t√≥picos do plano para seus sin√¥nimos
        all_target_tags = []
        for topico in plan.get("topicos", []):
            all_target_tags.extend(expand_search_terms(topico, alias_map, knowledge_base))
        all_target_tags = list(set(all_target_tags))
        
        tagged_context = ""
        for empresa in plan["empresas"]:
            tagged_results = search_by_tags(artifacts, empresa, all_target_tags)
            if tagged_results:
                tagged_context += f"--- Contexto de Alta Precis√£o para {empresa.upper()} (Tags Encontradas) ---\n"
                for res in tagged_results:
                    chunk_text = res['text']
                    if chunk_text not in unique_chunks:
                        source_url = res['source_url']
                        tagged_context += f"Fonte (Tag: '{res['tag_found']}'): {os.path.basename(source_url)}\n{chunk_text}\n\n"
                        unique_chunks.add(chunk_text)
                        sources.add(source_url)
        full_context += tagged_context

    with st.spinner("Executando busca sem√¢ntica para complementar o contexto..."):
        semantic_context = ""
        for empresa in plan["empresas"]:
            search_query = f"informa√ß√µes detalhadas sobre {', '.join(plan['topicos'])} no plano de remunera√ß√£o da empresa {empresa}"
            query_embedding = model.encode([search_query], normalize_embeddings=True)

            for category, artifact_data in artifacts.items():
                scores, indices = artifact_data['index'].search(query_embedding, TOP_K_SEARCH)
                for i, idx in enumerate(indices[0]):
                    if idx != -1 and scores[0][i] >= 0.35:
                        mapping = artifact_data["chunks"]["map"][idx]
                        if empresa.upper() == mapping.get("company_name", "").upper():
                            chunk_text = artifact_data["chunks"]["chunks"][idx]
                            if chunk_text not in unique_chunks:
                                source_url = mapping.get("source_url", "Fonte Desconhecida")
                                semantic_context += f"Fonte (Sem√¢ntica): {os.path.basename(source_url)} (Similaridade: {scores[0][i]:.2f})\n{chunk_text}\n\n"
                                unique_chunks.add(chunk_text)
                                sources.add(source_url)
        
        if semantic_context:
            full_context += "--- Contexto Adicional (Busca Sem√¢ntica Ampla) ---\n" + semantic_context

    return full_context, sources


def get_final_answer_with_dynamic_prompt(query: str, context: str):
    """
    (PROMPT DIN√ÇMICO) Gera a resposta final, adaptando o prompt com base no contexto.
    """
    if not GEMINI_API_KEY:
        st.error("Chave da API Gemini n√£o configurada. Verifique os segredos do Streamlit.")
        return "Erro: Chave da API n√£o encontrada."

    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    # L√≥gica do Prompt Din√¢mico
    structure_instruction = "Use formata√ß√£o Markdown (negrito, listas) para clareza e legibilidade."
    if "item 8.4" in query.lower():
        structure_instruction = """
        **ESTRUTURA OBRIGAT√ìRIA PARA ITEM 8.4:**
        Organize a resposta usando a estrutura oficial do item 8.4 do Formul√°rio de Refer√™ncia da CVM:
        a) Termos e condi√ß√µes gerais; b) Data de aprova√ß√£o e √≥rg√£o; c) M√°ximo de a√ß√µes; d) M√°ximo de op√ß√µes;
        e) Condi√ß√µes de aquisi√ß√£o; f) Crit√©rios de pre√ßo; g) Crit√©rios de prazo; h) Forma de liquida√ß√£o;
        i) Restri√ß√µes √† transfer√™ncia; j) Suspens√£o/extin√ß√£o; k) Efeitos da sa√≠da.
        Para cada subitem, extraia e organize as informa√ß√µes encontradas.
        """
    elif "Contexto de Alta Precis√£o" in context:
        structure_instruction = "PRIORIZE as informa√ß√µes da se√ß√£o 'Contexto de Alta Precis√£o (Tags Encontradas)', pois s√£o as mais relevantes. Use o 'Contexto Adicional' para complementar os detalhes. Organize a resposta de forma l√≥gica usando Markdown."

    prompt = f"""Voc√™ √© um consultor especialista em planos de remunera√ß√£o da CVM. Sua tarefa √© responder √† pergunta do usu√°rio de forma clara, profissional e em portugu√™s, baseando-se estritamente no contexto fornecido.

    **Instru√ß√µes Importantes:**
    1.  Use apenas as informa√ß√µes do 'Contexto Coletado'.
    2.  {structure_instruction}
    3.  Se a resposta n√£o estiver no contexto, afirme explicitamente: "A informa√ß√£o n√£o foi encontrada nos documentos analisados.". N√£o invente dados.

    **Pergunta do Usu√°rio:** "{query}"

    **Contexto Coletado dos Documentos:**
    ---
    {context}
    ---
    
    **Relat√≥rio Anal√≠tico Detalhado:**
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.1, "maxOutputTokens": 8192} # Aumentado para 8k
    }
    headers = {'Content-Type': 'application/json'}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        candidate = response.json().get('candidates', [{}])[0]
        content = candidate.get('content', {}).get('parts', [{}])[0]
        return content.get('text', "N√£o foi poss√≠vel gerar uma resposta.")
    except requests.exceptions.RequestException as e:
        logger.error(f"ERRO de requisi√ß√£o ao chamar a API Gemini: {e}")
        return f"Erro de comunica√ß√£o com a API do Gemini. Detalhes: {e}"
    except Exception as e:
        logger.error(f"ERRO inesperado ao processar resposta do Gemini: {e}")
        return f"Ocorreu um erro inesperado ao processar a resposta. Detalhes: {e}"


def handle_rag_query(query: str, artifacts: dict, model, company_catalog: list, alias_map: dict, knowledge_base: dict):
    """
    (ORQUESTRADOR ATUALIZADO) Orquestra o pipeline RAG H√≠brido e Din√¢mico.
    """
    with st.status("Gerando plano de an√°lise RAG...") as status:
        plan = create_dynamic_rag_plan(query, company_catalog, alias_map, knowledge_base)
        if not plan:
            st.error("N√£o consegui identificar empresas conhecidas na sua pergunta para realizar a an√°lise.")
            return set()
        status.update(label=f"Plano gerado. Analisando para: {', '.join(plan['empresas'])}...")

    # A execu√ß√£o agora √© a H√çBRIDA
    context, sources = execute_hybrid_rag_plan(plan, artifacts, model, alias_map, knowledge_base)
    
    if not context:
        st.warning("N√£o encontrei informa√ß√µes relevantes nos documentos para esta consulta.")
        return set()
    
    with st.spinner("Gerando relat√≥rio final com base no contexto coletado..."):
        # A gera√ß√£o de resposta agora usa o PROMPT DIN√ÇMICO
        final_answer = get_final_answer_with_dynamic_prompt(query, context)
        st.markdown(final_answer)
        
    return sources
    **Relat√≥rio Anal√≠tico Detalhado:**
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {"temperature": 0.1, "maxOutputTokens": 4096}
    }
    headers = {'Content-Type': 'application/json'}
    
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        # Extrai o texto da resposta da API
        candidate = response.json().get('candidates', [{}])[0]
        content = candidate.get('content', {}).get('parts', [{}])[0]
        return content.get('text', "N√£o foi poss√≠vel gerar uma resposta.")
    except requests.exceptions.RequestException as e:
        logger.error(f"ERRO de requisi√ß√£o ao chamar a API Gemini: {e}")
        return f"Erro de comunica√ß√£o com a API do Gemini. Detalhes: {e}"
    except Exception as e:
        logger.error(f"ERRO inesperado ao processar resposta do Gemini: {e}")
        return f"Ocorreu um erro inesperado ao processar a resposta. Detalhes: {e}"

def handle_rag_query(query: str, artifacts: dict, model, company_catalog: list, alias_map: dict):
    """
    (VERS√ÉO CORRIGIDA) Orquestra o pipeline RAG, chamando a fun√ß√£o de API correta.
    """
    with st.status("Gerando plano de an√°lise RAG...") as status:
        plan = create_rag_plan(query, company_catalog, alias_map)
        if not plan:
            st.error("N√£o consegui identificar empresas conhecidas na sua pergunta para realizar a an√°lise.")
            return set()
        status.update(label=f"Plano gerado. Analisando para: {', '.join(plan['empresas'])}...")

    with st.spinner("Recuperando e analisando informa√ß√µes..."):
        context, sources = execute_rag_plan(plan, artifacts, model)
        if not context:
            st.warning("N√£o encontrei informa√ß√µes relevantes nos documentos para esta consulta.")
            return set()
        
        # Chamada para a fun√ß√£o de API correta e funcional
        final_answer = get_final_unified_answer(query, context)
        st.markdown(final_answer)
        
    return sources

@st.cache_data
def criar_mapa_de_alias(knowledge_base: dict):
    """
    (VERS√ÉO CORRIGIDA) Cria um dicion√°rio que mapeia cada apelido E o pr√≥prio nome do t√≥pico 
    ao seu t√≥pico can√¥nico, recebendo a base de conhecimento como argumento.
    """
    alias_to_canonical = {}
    for section, topics in knowledge_base.items():
        for canonical_name, aliases in topics.items():
            alias_to_canonical[canonical_name.lower()] = canonical_name
            for alias in aliases:
                alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical

def main():
    st.set_page_config(
        page_title="Agente de An√°lise LTIP", 
        page_icon="ü§ñ", 
        layout="wide", 
        initial_sidebar_state="expanded"
    )
    st.title("ü§ñ Agente de An√°lise de Planos de Incentivo (ILP)")
    
    # --- Carregamento Centralizado de Dados e Artefatos ---
    with st.spinner("Carregando modelos, √≠ndices e base de conhecimento..."):
        model, artifacts, summary_data = load_all_artifacts()
    
    try:
        from knowledge_base import DICIONARIO_UNIFICADO_HIERARQUICO
        logger.info("Base de conhecimento 'knowledge_base.py' carregada.")
    except ImportError:
        st.error("ERRO CR√çTICO: Crie o arquivo 'knowledge_base.py' e cole o 'DICIONARIO_UNIFICADO_HIERARQUICO' nele.")
        st.stop()
        
    ALIAS_MAP = criar_mapa_de_alias(DICIONARIO_UNIFICADO_HIERARQUICO)

    try:
        from catalog_data import company_catalog_rich
        logger.info("Cat√°logo de empresas 'catalog_data.py' carregado.")
    except ImportError:
        logger.warning("`catalog_data.py` n√£o encontrado. Criando cat√°logo din√¢mico a partir do resumo.")
        if summary_data:
            company_catalog_rich = [{"canonical_name": name, "aliases": [name.split(' ')[0].lower(), name.lower()]} for name in summary_data.keys()]
        else:
            company_catalog_rich = []
            st.warning("Cat√°logo de empresas n√£o p√¥de ser criado pois o arquivo de resumo tamb√©m est√° ausente.")

    # --- Sidebar com Informa√ß√µes do Sistema (Inspirado no script original) ---
    with st.sidebar:
        st.header("üìä Informa√ß√µes do Sistema")
        st.metric("Fontes de Documentos (RAG)", len(artifacts) if artifacts else "N/A")
        st.metric("Empresas no Resumo", len(summary_data) if summary_data else "N/A")
        
        if summary_data:
            with st.expander("Empresas com dados para an√°lise r√°pida"):
                empresas_df = pd.DataFrame(sorted(list(summary_data.keys())), columns=["Nome da Empresa"])
                st.dataframe(empresas_df, use_container_width=True, hide_index=True)
        
        st.success("‚úÖ Sistema pronto para an√°lise")
        st.info(f"**Modelo de Embedding:**\n`{MODEL_NAME}`")
        st.info(f"**Modelo Generativo:**\n`{GEMINI_MODEL}`")

    # --- Bloco de Orienta√ß√£o ao Usu√°rio (Inspirado no script original) ---
    st.header("üí¨ Fa√ßa sua pergunta")
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    with col1:
        st.info("**Experimente an√°lises r√°pidas (sem RAG):**")
        st.code("Quais empresas possuem planos com matching?") # Agregada
        st.code("Qual o desconto m√©dio oferecido?") # Anal√≠tica
        st.code("Qual o per√≠odo de vesting da Movida?") # Fato Direto
    with col2:
        st.info("**Ou uma an√°lise profunda (com RAG):**")
        st.code("Compare as pol√≠ticas de dividendos da Vale e Gerdau") # Comparativa
        st.code("Como √© o tratamento de desligamento no plano da Magazine Luiza?") # Detalhada
        st.code("Resumo completo do item 8.4 da Vivo") # Estruturada

    st.caption("**Principais Termos-Chave:** `Item 8.4`, `Vesting`, `Stock Options`, `A√ß√µes Restritas`, `Performance`, `Matching`, `Lockup`, `SAR`, `ESPP`, `Malus e Clawback`, `Dividendos`, `Good Leaver`, `Bad Leaver`")

    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Quantas empresas oferecem a√ß√µes restritas e possuem cl√°usula de clawback?")

    if st.button("üîç Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
            st.stop()

        st.markdown("---")
        st.subheader("üìã Resultado da An√°lise")
        
        # --- ROTEADOR DE INTEN√á√ÉO DE 4 N√çVEIS COM FEEDBACK PARA O USU√ÅRIO ---
        query_lower = user_query.lower()
        analytical_keywords = ['medio', 'm√©dia', 't√≠pico', 'menor', 'm√≠nimo', 'maior', 'm√°ximo']
        aggregate_keywords = ["quais", "quantas", "liste", "mostre"]
        direct_fact_pattern = r'qual\s*(?:√©|o|a)\s*.*\s*d[aeo]\s*'
        sources = set()

        if any(keyword in query_lower for keyword in analytical_keywords):
            st.info("Detectada uma pergunta **anal√≠tica (m√©dia, m√≠nimo, m√°ximo)**. Buscando nos dados pr√©-processados...")
            if not handle_analytical_query(user_query, summary_data):
                st.warning("A an√°lise r√°pida n√£o encontrou dados num√©ricos. Acionando a an√°lise profunda (RAG) para uma resposta mais completa...")
                sources = handle_rag_query(user_query, artifacts, model, company_catalog_rich, ALIAS_MAP, DICIONARIO_UNIFICADO_HIERARQUICO)
        
        elif any(keyword in query_lower for keyword in aggregate_keywords):
            st.info("Detectada uma pergunta **agregada (quais, quantas)**. Buscando na lista de empresas...")
            if not summary_data:
                st.error("A funcionalidade de busca agregada est√° desativada pois o arquivo de resumo n√£o foi encontrado.")
            else:
                handle_aggregate_query(user_query, summary_data, ALIAS_MAP)
        
        elif re.search(direct_fact_pattern, query_lower) and any(comp["canonical_name"].lower() in query_lower for comp in company_catalog_rich):
            st.info("Detectada uma pergunta de **fato direto**. Buscando nos fatos extra√≠dos...")
            if not handle_direct_fact_query(user_query, summary_data, ALIAS_MAP, company_catalog_rich):
                st.warning("N√£o encontrei um fato estruturado. Acionando a an√°lise profunda (RAG) para buscar no texto completo...")
                sources = handle_rag_query(user_query, artifacts, model, company_catalog_rich, ALIAS_MAP, DICIONARIO_UNIFICADO_HIERARQUICO)
        
        else:
            st.info("Detectada uma pergunta **detalhada ou comparativa**. Acionando a an√°lise profunda (RAG)...")
            if not artifacts:
                 st.error("A funcionalidade de an√°lise profunda est√° desativada pois os √≠ndices de busca n√£o foram encontrados.")
            else:
                sources = handle_rag_query(user_query, artifacts, model, company_catalog_rich, ALIAS_MAP, DICIONARIO_UNIFICADO_HIERARQUICO)

        # --- Exibi√ß√£o das Fontes Consultadas (Apenas para o RAG) ---
        if sources:
            st.markdown("---")
            with st.expander(f"üìö Fontes consultadas na an√°lise profunda ({len(sources)})", expanded=False):
                # Usando um DataFrame para uma visualiza√ß√£o mais limpa
                sources_df = pd.DataFrame(sorted(list(sources)), columns=["Documento"])
                st.dataframe(sources_df, use_container_width=True, hide_index=True)

if __name__ == "__main__":
    main()
