# -*- coding: utf-8 -*-
"""
AGENTE DE AN√ÅLISE LTIP - VERS√ÉO STREAMLIT (H√çBRIDO)
Aplica√ß√£o web para an√°lise de planos de incentivo de longo prazo, com
capacidades de busca profunda (RAG) e an√°lise agregada (resumo).
"""

import streamlit as st
import json
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
import requests
import glob
import os
import re
import unicodedata
import logging
from functools import lru_cache

# --- CONFIGURA√á√ïES GERAIS ---
MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'
TOP_K_SEARCH = 7
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
DADOS_PATH = "dados" # Centraliza o caminho para a pasta de dados

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- DICION√ÅRIOS DE CONHECIMENTO ---

# Dicion√°rio principal para tradu√ß√£o de termos e busca de t√≥picos
TERMOS_TECNICOS_LTIP = {
    "A√ß√µes Restritas": ["Restricted Shares", "Plano de A√ß√µes Restritas", "Outorga de A√ß√µes", "a√ß√µes restritas", "RSU"],
    "Op√ß√µes de Compra de A√ß√µes": ["Stock Options", "ESOP", "Plano de Op√ß√£o de Compra", "Outorga de Op√ß√µes", "op√ß√µes", "Plano de Op√ß√£o", "Plano de Op√ß√µes", "SOP"],
    "A√ß√µes Fantasmas": ["Phantom Shares", "A√ß√µes Virtuais"],
    "Op√ß√µes Fantasmas (SAR)": ["Phantom Options", "SAR", "Share Appreciation Rights", "Direito √† Valoriza√ß√£o de A√ß√µes"],
    "B√¥nus Diferido": ["Staying Bonus", "Retention Bonus", "B√¥nus de Perman√™ncia", "B√¥nus de Reten√ß√£o", "b√¥nus"],
    "Planos com Condi√ß√£o de Performance": ["Performance Shares", "Performance Stock Options", "Plano de Desempenho", "Metas de Performance", "performance", "desempenho"],
    "Vesting": ["Vesting", "Per√≠odo de Car√™ncia", "Condi√ß√µes de Car√™ncia", "Aquisi√ß√£o de Direitos", "car√™ncia", "cronograma de vesting"],
    "Antecipa√ß√£o de Vesting": ["Vesting Acelerado", "Accelerated Vesting", "Cl√°usula de Acelera√ß√£o", "antecipa√ß√£o de car√™ncia", "antecipa√ß√£o do vesting", "antecipa√ß√£o"],
    "Tranche / Lote": ["Tranche", "Lote", "Parcela do Vesting"],
    "Cliff": ["Cliff Period", "Per√≠odo de Cliff", "Car√™ncia Inicial"],
    "Matching": ["Matching", "Contrapartida", "Co-investimento", "Plano de Matching", "investimento"],
    "Lockup": ["Lockup", "Per√≠odo de Lockup", "Restri√ß√£o de Venda"],
    "Estrutura do Plano/Programa": ["Plano", "Planos", "Programa", "Programas", "termos e condi√ß√µes gerais"],
    "Ciclo de Vida do Exerc√≠cio": ["pagamento", "liquida√ß√£o", "vencimento", "expira√ß√£o", "forma de liquida√ß√£o"],
    "Eventos Corporativos": ["IPO", "grupamento", "desdobramento", "bonifica√ß√µes", "bonifica√ß√£o"],
    "Dividendos": ["Dividendos", "Dividendo", "JCP", "Juros sobre capital pr√≥prio", "Tratamento de Dividendos", "equivalente em dividendos", "proventos"],
    "Encargos": ["Encargos", "Impostos", "Tributa√ß√£o", "Natureza Mercantil", "Natureza Remunerat√≥ria", "INSS", "IRRF"],
}

# T√≥picos para o fallback do LLM na an√°lise profunda (RAG)
AVAILABLE_TOPICS = list(TERMOS_TECNICOS_LTIP.keys()) + [
    "data de aprova√ß√£o e √≥rg√£o respons√°vel", "n√∫mero m√°ximo de a√ß√µes abrangidas", "n√∫mero m√°ximo de op√ß√µes a serem outorgadas",
    "crit√©rios para fixa√ß√£o do pre√ßo de aquisi√ß√£o ou exerc√≠cio", "pre√ßo de exerc√≠cio", "strike price", "restri√ß√µes √† transfer√™ncia das a√ß√µes",
    "crit√©rios e eventos de suspens√£o/extin√ß√£o", "efeitos da sa√≠da do administrador"
]

# --- CARREGAMENTO DE DADOS E CACHING ---

@st.cache_resource
def load_all_artifacts():
    """
    Carrega todos os artefatos necess√°rios para a aplica√ß√£o:
    - Modelo de embedding
    - √çndices FAISS e chunks (para RAG)
    - Resumo de caracter√≠sticas (para buscas agregadas)
    """
    # 1. Carregar Modelo de Embedding
    model = SentenceTransformer(MODEL_NAME)
    
    # 2. Carregar Artefatos do RAG (FAISS e Chunks)
    artifacts = {}
    index_files = glob.glob(os.path.join(DADOS_PATH, '*_faiss_index.bin'))
    if not index_files:
        logger.error("Nenhum arquivo de √≠ndice FAISS encontrado na pasta 'dados'. O RAG n√£o funcionar√°.")
    else:
        for index_file in index_files:
            category = os.path.basename(index_file).replace('_faiss_index.bin', '')
            chunks_file = os.path.join(DADOS_PATH, f"{category}_chunks_map.json")
            try:
                index = faiss.read_index(index_file)
                with open(chunks_file, 'r', encoding='utf-8') as f:
                    chunk_data = json.load(f)
                artifacts[category] = {'index': index, 'chunks': chunk_data}
            except FileNotFoundError:
                logger.warning(f"Arquivo de chunks para a categoria '{category}' n√£o encontrado. Pulando.")
                continue
    
    # 3. Carregar Resumo de Caracter√≠sticas
    summary_data = None
    summary_file_path = os.path.join(DADOS_PATH, 'resumo_caracteristicas.json')
    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
    except FileNotFoundError:
        logger.error("Arquivo 'resumo_caracteristicas.json' n√£o encontrado. Buscas agregadas n√£o funcionar√£o.")
        
    return model, artifacts, summary_data

@st.cache_data
def criar_mapa_de_alias():
    """
    Cria um dicion√°rio que mapeia cada apelido ao seu t√≥pico can√¥nico para buscas r√°pidas.
    Ex: {'performance': 'Planos com Condi√ß√£o de Performance'}
    """
    alias_to_canonical = {}
    for canonical_name, aliases in TERMOS_TECNICOS_LTIP.items():
        for alias in aliases:
            alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical

# --- FUN√á√ïES DE L√ìGICA DE NEG√ìCIO (ROTEADOR E MANIPULADORES) ---

def handle_aggregate_query(query, summary_data, alias_map):
    """
    Lida com perguntas agregadas ("quais", "quantas").
    Retorna a resposta formatada como uma string Markdown.
    """
    query_lower = query.lower()
    
    # 1. Extrair o t√≥pico da pergunta usando o mapa de alias
    topico_canonico_encontrado = None
    # Iterar pelas chaves ordenadas pela mais longa primeiro para evitar correspond√™ncias parciais
    sorted_aliases = sorted(alias_map.keys(), key=len, reverse=True)
    
    for alias in sorted_aliases:
        if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
            topico_canonico_encontrado = alias_map[alias]
            break

    if not topico_canonico_encontrado:
        return "N√£o consegui identificar um t√≥pico conhecido (como 'performance', 'matching', 'op√ß√µes') na sua pergunta para fazer a busca. Por favor, tente novamente."

    # 2. Buscar as empresas no JSON
    empresas_encontradas = []
    if summary_data:
        for empresa, dados in summary_data.items():
            if topico_canonico_encontrado in dados.get("topicos_encontrados", []):
                empresas_encontradas.append(empresa)
    
    empresas_encontradas.sort()

    # 3. Formatar a resposta
    if not empresas_encontradas:
        return f"Nenhuma empresa foi encontrada com planos sobre **'{topico_canonico_encontrado}'** nos documentos analisados."

    num_empresas = len(empresas_encontradas)
    
    if "quantas" in query_lower:
        return f"‚úÖ **{num_empresas} empresa(s)** encontrada(s) com planos sobre **'{topico_canonico_encontrado}'**."

    resposta_md = f"‚úÖ **{num_empresas} empresa(s)** encontrada(s) com planos sobre **'{topico_canonico_encontrado}'**:\n\n"
    
    if num_empresas > 0:
        # Apresenta em at√© 3 colunas para melhor visualiza√ß√£o
        num_cols = min(3, num_empresas)
        cols = st.columns(num_cols)
        for i, empresa in enumerate(empresas_encontradas):
            with cols[i % num_cols]:
                st.markdown(f"- {empresa}")
    
    # Retorna a parte textual, as colunas s√£o renderizadas diretamente
    return resposta_md


def handle_rag_query(query, artifacts, model, company_catalog_rich):
    """
    Lida com perguntas detalhadas e comparativas usando o fluxo RAG completo.
    """
    # ETAPA 1: GERA√á√ÉO DO PLANO
    with st.status("1Ô∏è‚É£ Gerando plano de an√°lise...", expanded=True) as status:
        # Nota: Idealmente, company_catalog_rich seria carregado uma vez fora.
        # Por simplicidade, mantemos aqui.
        plan_response = create_dynamic_analysis_plan_v2(query, company_catalog_rich, list(artifacts.keys()))
        if plan_response['status'] != "success" or not plan_response['plan']['empresas']:
            st.error("‚ùå N√£o consegui identificar empresas na sua pergunta. Tente usar nomes conhecidos (ex: Magalu, Vivo, Ita√∫).")
            return "An√°lise abortada.", set()
        
        plan = plan_response['plan']
        empresas = plan.get('empresas', [])
        st.write(f"**üè¢ Empresas identificadas:** {', '.join(empresas)}")
        st.write(f"**üìù T√≥picos a analisar:** {len(plan.get('topicos', []))}")
        status.update(label="‚úÖ Plano gerado com sucesso!", state="complete")

    # ETAPA 2: L√ìGICA DE EXECU√á√ÉO (com tratamento para compara√ß√µes)
    final_answer = ""
    sources = set()

    # MODO COMPARATIVO
    if len(empresas) > 1:
        st.info(f"Modo de compara√ß√£o ativado para {len(empresas)} empresas. Analisando sequencialmente...")
        summaries = []
        for i, empresa in enumerate(empresas):
            with st.status(f"Analisando {i+1}/{len(empresas)}: {empresa}...", expanded=True):
                single_company_plan = {'empresas': [empresa], 'topicos': plan['topicos']}
                query_intent = 'item_8_4_query' if any(term in query.lower() for term in ['8.4', 'formul√°rio']) else 'general_query'
                retrieved_context, retrieved_sources = execute_dynamic_plan(single_company_plan, query_intent, artifacts, model)
                sources.update(retrieved_sources)

                if "Nenhuma informa√ß√£o" in retrieved_context or not retrieved_context.strip():
                    summary = f"## An√°lise para {empresa.upper()}\n\nNenhuma informa√ß√£o encontrada nos documentos para os t√≥picos solicitados."
                else:
                    summary_prompt = f"Com base no contexto a seguir sobre a empresa {empresa}, resuma os pontos principais sobre os seguintes t√≥picos: {', '.join(plan['topicos'])}. Contexto: {retrieved_context}"
                    summary = get_final_unified_answer(summary_prompt, retrieved_context)
                
                summaries.append(f"--- RESUMO PARA {empresa.upper()} ---\n\n{summary}")

        with st.status("Gerando relat√≥rio comparativo final...", expanded=True):
            comparison_prompt = f"Com base nos resumos individuais a seguir, crie um relat√≥rio comparativo detalhado e bem estruturado entre as empresas, focando nos pontos levantados na pergunta original do usu√°rio.\n\nPergunta original do usu√°rio: '{query}'\n\n" + "\n\n".join(summaries)
            final_answer = get_final_unified_answer(comparison_prompt, "\n\n".join(summaries))
            status.update(label="‚úÖ Relat√≥rio comparativo gerado!", state="complete")

    # MODO DE AN√ÅLISE √öNICA
    else:
        with st.status("2Ô∏è‚É£ Recuperando contexto relevante...", expanded=True) as status:
            query_intent = 'item_8_4_query' if any(term in query.lower() for term in ['8.4', 'formul√°rio']) else 'general_query'
            st.write(f"**üéØ Estrat√©gia detectada:** {'Item 8.4 completo' if query_intent == 'item_8_4_query' else 'Busca geral'}")
            
            retrieved_context, retrieved_sources = execute_dynamic_plan(plan, query_intent, artifacts, model)
            sources.update(retrieved_sources)
            
            if not retrieved_context.strip() or "Nenhuma informa√ß√£o encontrada" in retrieved_context:
                st.error("‚ùå N√£o encontrei informa√ß√µes relevantes nos documentos para a sua consulta.")
                return "Nenhuma informa√ß√£o relevante encontrada.", set()
            
            st.write(f"**üìÑ Contexto recuperado de:** {len(sources)} documento(s)")
            status.update(label="‚úÖ Contexto recuperado com sucesso!", state="complete")
        
        with st.status("3Ô∏è‚É£ Gerando resposta final...", expanded=True) as status:
            final_answer = get_final_unified_answer(query, retrieved_context)
            status.update(label="‚úÖ An√°lise conclu√≠da!", state="complete")

    return final_answer, sources

# --- FUN√á√ïES DE BACKEND (RAG) - sem altera√ß√µes ---

# Mantidas as fun√ß√µes originais para o fluxo RAG
def create_dynamic_analysis_plan_v2(query, company_catalog_rich, available_indices):
    # Esta fun√ß√£o agora √© chamada apenas pelo `handle_rag_query`
    api_key = GEMINI_API_KEY
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key={api_key}"
    query_lower = query.lower().strip()
    
    # Identifica√ß√£o de Empresas
    mentioned_companies = []
    companies_found_by_alias = {}
    if company_catalog_rich:
        for company_data in company_catalog_rich:
            for alias in company_data.get("aliases", []):
                if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                    score = len(alias.split())
                    canonical_name = company_data["canonical_name"]
                    if canonical_name not in companies_found_by_alias or score > companies_found_by_alias[canonical_name]:
                        companies_found_by_alias[canonical_name] = score
        if companies_found_by_alias:
            sorted_companies = sorted(companies_found_by_alias.items(), key=lambda item: item[1], reverse=True)
            mentioned_companies = [company for company, score in sorted_companies]
    
    if not mentioned_companies:
        return {"status": "error", "plan": {}}
    
    # Identifica√ß√£o de T√≥picos
    topics = []
    found_topics = set()
    alias_map = criar_mapa_de_alias() # Reutiliza o mapa de alias
    for alias, canonical_name in alias_map.items():
        if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
            found_topics.add(canonical_name)

    if found_topics:
        topics = list(found_topics)
    else:
        # Fallback para LLM se nenhum t√≥pico for encontrado
        prompt = f"""Voc√™ √© um consultor de ILP. Identifique os T√ìPICOS CENTRAIS da pergunta: "{query}".
        Retorne APENAS uma lista JSON com os t√≥picos mais relevantes de: {json.dumps(AVAILABLE_TOPICS)}.
        Se for gen√©rica, selecione t√≥picos para uma an√°lise geral. Formato: ["T√≥pico 1", "T√≥pico 2"]"""
        payload = {"contents": [{"parts": [{"text": prompt}]}]}
        headers = {'Content-Type': 'application/json'}
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=90)
            response.raise_for_status()
            text_response = response.json()['candidates'][0]['content']['parts'][0]['text']
            json_match = re.search(r'\[.*\]', text_response, re.DOTALL)
            if json_match:
                topics = json.loads(json_match.group(0))
            else:
                topics = ["Estrutura do Plano/Programa", "Vesting", "Op√ß√µes de Compra de A√ß√µes"]
        except Exception as e:
            logger.error(f"Falha ao chamar LLM para t√≥picos: {e}")
            topics = ["Estrutura do Plano/Programa", "Vesting", "Op√ß√µes de Compra de A√ß√µes"]
            
    plan = {"empresas": mentioned_companies, "topicos": topics}
    return {"status": "success", "plan": plan}


def execute_dynamic_plan(plan, query_intent, artifacts, model):
    """
    Executa o plano de busca com controle robusto de tokens e deduplica√ß√£o.
    (Esta fun√ß√£o permanece exatamente como no seu c√≥digo original)
    """
    # ... (Cole aqui o corpo inteiro da sua fun√ß√£o `execute_dynamic_plan` original)
    # Nenhuma altera√ß√£o √© necess√°ria nesta fun√ß√£o.
    # Por brevidade, o corpo foi omitido aqui, mas deve ser colado integralmente.
    full_context = "Contexto recuperado pela fun√ß√£o execute_dynamic_plan." # Placeholder
    all_retrieved_docs = {"doc1.pdf", "doc2.pdf"} # Placeholder
    return full_context, all_retrieved_docs


def get_final_unified_answer(query, context):
    """
    Gera a resposta final usando o contexto recuperado.
    (Esta fun√ß√£o permanece exatamente como no seu c√≥digo original)
    """
    # ... (Cole aqui o corpo inteiro da sua fun√ß√£o `get_final_unified_answer` original)
    # Nenhuma altera√ß√£o √© necess√°ria nesta fun√ß√£o.
    # Por brevidade, o corpo foi omitido aqui, mas deve ser colado integralmente.
    return f"Resposta final gerada por LLM para a query: '{query}' com base no contexto." # Placeholder


# --- INTERFACE STREAMLIT (Aplica√ß√£o Principal) ---
def main():
    st.set_page_config(page_title="Agente de An√°lise LTIP", page_icon="üîç", layout="wide", initial_sidebar_state="expanded")
    st.title("ü§ñ Agente de An√°lise de Planos de Incentivo (ILP)")
    st.markdown("---")

    # Carregamento centralizado dos artefatos
    model, artifacts, summary_data = load_all_artifacts()
    ALIAS_MAP = criar_mapa_de_alias()

    # Tenta carregar o cat√°logo de empresas, mas n√£o quebra se n√£o encontrar
    try:
        from catalog_data import company_catalog_rich
    except ImportError:
        company_catalog_rich = []
        logger.warning("`catalog_data.py` n√£o encontrado. A identifica√ß√£o de empresas por apelidos ser√° limitada.")

    # Valida√ß√£o dos dados carregados
    if not artifacts:
        st.error("‚ùå Erro cr√≠tico: Nenhum artefato de busca (√≠ndices FAISS) foi carregado. A an√°lise profunda est√° desativada.")
    if not summary_data:
        st.warning("‚ö†Ô∏è Aviso: O arquivo `resumo_caracteristicas.json` n√£o foi encontrado. An√°lises de 'quais/quantas empresas' est√£o desativadas.")
    
    # --- Sidebar ---
    with st.sidebar:
        st.header("üìä Informa√ß√µes do Sistema")
        st.metric("Fontes de Documentos (RAG)", len(artifacts) if artifacts else 0)
        st.metric("Empresas no Resumo", len(summary_data) if summary_data else 0)
        
        if summary_data:
            with st.expander("empresas com caracter√≠sticas identificadas"):
                st.dataframe(sorted(list(summary_data.keys())), use_container_width=True)
        
        st.success("‚úÖ Sistema pronto para an√°lise")
        st.info(f"Modelo de embedding: `{MODEL_NAME}`")

    # --- Corpo Principal ---
    st.header("üí¨ Fa√ßa sua pergunta")
    
    # Colunas para exemplos de perguntas
    col1, col2 = st.columns(2)
    with col1:
        st.info("**Experimente uma an√°lise agregada:**")
        st.code("Quais empresas possuem planos com matching?")
        st.code("Quantas empresas t√™m vesting acelerado?")
    with col2:
        st.info("**Ou uma an√°lise profunda (RAG):**")
        st.code("Compare o vesting da Vale com a Petrobras")
        st.code("Como funciona o lockup da Magazine Luiza?")

    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Quantas empresas oferecem a√ß√µes restritas?")

    if st.button("üîç Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
            return

        st.markdown("---")
        st.subheader("üìã Resultado da An√°lise")
        
        # --- O ROTEADOR DE INTEN√á√ÉO EM A√á√ÉO ---
        final_answer = ""
        sources = set()
        
        query_lower = user_query.lower()
        aggregate_keywords = ["quais", "quantas", "liste", "qual a lista de"]

        # Rota 1: Pergunta agregada
        if any(keyword in query_lower for keyword in aggregate_keywords):
            if not summary_data:
                st.error("A funcionalidade de busca agregada est√° desativada pois o arquivo `resumo_caracteristicas.json` n√£o foi encontrado.")
            else:
                st.info("Detectada uma pergunta agregada. Buscando no resumo de caracter√≠sticas...")
                with st.spinner("Analisando resumo..."):
                    # A fun√ß√£o `handle_aggregate_query` agora pode renderizar colunas diretamente
                    # e retornar o texto principal.
                    final_answer_text_part = handle_aggregate_query(user_query, summary_data, ALIAS_MAP)
                    st.markdown(final_answer_text_part) # Renderiza o texto e as colunas (se houver)

        # Rota 2: Pergunta profunda (RAG)
        else:
            if not artifacts:
                st.error("A funcionalidade de an√°lise profunda est√° desativada pois os √≠ndices de busca n√£o foram encontrados.")
            elif not company_catalog_rich:
                 st.error("A funcionalidade de an√°lise profunda est√° desativada pois o `catalog_data.py` n√£o foi encontrado.")
            else:
                st.info("Detectada uma pergunta detalhada. Acionando an√°lise profunda (RAG)...")
                final_answer, sources = handle_rag_query(user_query, artifacts, model, company_catalog_rich)
                st.markdown(final_answer) # Renderiza a resposta do RAG

        # Fontes consultadas (apenas para o RAG)
        if sources:
            st.markdown("---")
            with st.expander(f"üìö Documentos consultados na an√°lise profunda ({len(sources)})", expanded=False):
                for i, source in enumerate(sorted(list(sources)), 1):
                    st.write(f"{i}. {source}")

if __name__ == "__main__":
    main()
