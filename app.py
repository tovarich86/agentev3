# app.py (VERSÃƒO CORRIGIDA)

import streamlit as st
import json
import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, CrossEncoder
from collections import defaultdict
import requests
import re
import unicodedata
import logging
from pathlib import Path
import zipfile
import io
import base64
import shutil
import random
from models import get_embedding_model, get_cross_encoder_model
from concurrent.futures import ThreadPoolExecutor
from tools import (
    find_companies_by_topic,
    get_final_unified_answer,
    suggest_alternative_query,
    analyze_topic_thematically,
    get_summary_for_topic_at_company,
    rerank_with_cross_encoder,
    create_hierarchical_alias_map,
    rerank_by_recency
    )

# --- MÃ³dulos do Projeto ---
from knowledge_base import DICIONARIO_UNIFICADO_HIERARQUICO
from analytical_engine import AnalyticalEngine

# ==============================================================================
# 1. CONFIGURAÃ‡ÃƒO DA PÃGINA - DEVE SER O PRIMEIRO COMANDO STREAMLIT
# ==============================================================================
st.set_page_config(page_title="Agente de AnÃ¡lise ILP", page_icon="ğŸ”", layout="wide", initial_sidebar_state="expanded")

# ==============================================================================
# 2. INJEÃ‡ÃƒO DE CSS CUSTOMIZADO (BACKGROUND E FONTES)
# ==============================================================================

# URL da imagem "raw" do seu GitHub
image_url = "https://raw.githubusercontent.com/tovarich86/agentev3/main/prisday.png"

# CSS para aplicar o background e as fontes
page_bg_img = f"""
<style>
/* Importa as fontes do Google Fonts */
@import url('https://fonts.googleapis.com/css2?family=Fira+Sans:wght@400;700&family=Nunito+Sans:wght@400;700;800;900&display=swap');

/* Aplica a imagem de fundo usando a URL do GitHub */
[data-testid="stAppViewContainer"] > .main {{
    background-image: url("{image_url}");
    background-size: cover;
    background-position: top left;
    background-repeat: no-repeat;
    background-attachment: local; /* Garante que a imagem role com o conteÃºdo */
}}

/* Deixa o header transparente para a imagem aparecer */
[data-testid="stHeader"] {{
    background: rgba(0,0,0,0);
}}

/* Ajusta a posiÃ§Ã£o da barra de ferramentas do Streamlit */
[data-testid="stToolbar"] {{
    right: 2rem;
}}

/* --- ESTILOS DE FONTE --- */

/* Define a fonte padrÃ£o para o corpo do texto */
html, body, [class*="css"] {{
    font-family: 'Nunito Sans', sans-serif;
    font-weight: 400;
}}

/* Define a fonte para os tÃ­tulos e subtÃ­tulos */
h1, h2, h3, h4, h5, h6 {{
    font-family: 'Fira Sans', sans-serif;
    font-weight: 700; /* Bold */
}}

/* Customiza a fonte dos botÃµes */
.stButton>button {{
    font-family: 'Nunito Sans', sans-serif;
    font-weight: 700;
}}
</style>
"""

st.markdown(page_bg_img, unsafe_allow_html=True)


# ==============================================================================
# O RESTO DO SEU CÃ“DIGO COMEÃ‡A AQUI
# ==============================================================================

# --- Constantes e ConfiguraÃ§Ãµes ---
MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
TOP_K_SEARCH = 7
TOP_K_INITIAL_RETRIEVAL = 30
TOP_K_FINAL = 15
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-2.0-flash-lite" # Recomendo usar um modelo mais recente se possÃ­vel
CVM_SEARCH_URL = "https://www.rad.cvm.gov.br/ENET/frmConsultaExternaCVM.aspx"

FILES_TO_DOWNLOAD = {
    "item_8_4_chunks_map_final.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/item_8_4_chunks_map.json",
    "item_8_4_faiss_index_final.bin": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/item_8_4_faiss_index.bin",
    "outros_documentos_chunks_map_final.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/outros_documentos_chunks_map.json",
    "outros_documentos_faiss_index_final.bin": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/outros_documentos_faiss_index.bin",
    "resumo_fatos_e_topicos_final_enriquecido.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/resumo_fatos_e_topicos_v4_por_data.json"
}
CACHE_DIR = Path("data_cache")
SUMMARY_FILENAME = "resumo_fatos_e_topicos_final_enriquecido.json"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- CARREGADOR DE DADOS ---
@st.cache_resource(show_spinner="Configurando o ambiente e baixando dados...")
def setup_and_load_data():
    CACHE_DIR.mkdir(exist_ok=True)
    
    for filename, url in FILES_TO_DOWNLOAD.items():
        local_path = CACHE_DIR / filename
        if not local_path.exists():
            logger.info(f"Baixando arquivo '{filename}'...")
            try:
                response = requests.get(url, stream=True, timeout=60)
                response.raise_for_status()
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                logger.info(f"'{filename}' baixado com sucesso.")
            except requests.exceptions.RequestException as e:
                st.error(f"Erro ao baixar {filename} de {url}: {e}")
                st.stop()
    # --- Carregamento de Modelos ---
    
    embedding_model = SentenceTransformer(MODEL_NAME)
    
    
    cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    artifacts = {}
    for index_file in CACHE_DIR.glob('*_faiss_index_final.bin'):
        category = index_file.stem.replace('_faiss_index_final', '')
        chunks_file = CACHE_DIR / f"{category}_chunks_map_final.json"
        try:
            with open(chunks_file, 'r', encoding='utf-8') as f:
                list_of_chunks = json.load(f)
                
            artifacts[category] = {
                'index': faiss.read_index(str(index_file)),
                'chunks': list_of_chunks
            }
        except Exception as e:
            st.error(f"Falha ao carregar artefatos para a categoria '{category}': {e}")
            st.stop()

    summary_file_path = CACHE_DIR / SUMMARY_FILENAME
    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
    except FileNotFoundError:
        st.error(f"Erro crÃ­tico: '{SUMMARY_FILENAME}' nÃ£o foi encontrado.")
        st.stop()

    setores = set()
    controles = set()

    for artifact_data in artifacts.values():
        chunk_map = artifact_data.get('chunks', [])
        for metadata in chunk_map:
            setor = metadata.get('setor')
            if isinstance(setor, str) and setor.strip():
                setores.add(setor.strip().capitalize())
            else:
                setores.add("NÃ£o identificado")

            controle = metadata.get('controle_acionario')
            if isinstance(controle, str) and controle.strip():
                controles.add(controle.strip().capitalize())
            else:
                controles.add("NÃ£o identificado")

    sorted_setores = sorted([s for s in setores if s != "NÃ£o Informado"])
    if "NÃ£o Informado" in setores:
        sorted_setores.append("NÃ£o Informado")

    sorted_controles = sorted([c for c in controles if c != "NÃ£o Informado"])
    if "NÃ£o Informado" in controles:
        sorted_controles.append("NÃ£o Informado")

    all_setores = ["Todos"] + sorted_setores
    all_controles = ["Todos"] + sorted_controles

    logger.info(f"Filtros dinÃ¢micos encontrados: {len(all_setores)-1} setores e {len(all_controles)-1} tipos de controle.")
    
    return artifacts, summary_data, all_setores, all_controles, embedding_model, cross_encoder_model

# ... (o resto do seu cÃ³digo, desde a funÃ§Ã£o _create_flat_alias_map, permanece exatamente o mesmo)
# --- FUNÃ‡Ã•ES GLOBAIS E DE RAG ---
def convert_numpy_types(o):
    """
    Percorre recursivamente uma estrutura de dados (dicionÃ¡rios, listas) e converte
    os tipos numÃ©ricos do NumPy para os tipos nativos do Python, tornando-a
    serializÃ¡vel para JSON.
    """
    if isinstance(o, (np.int64, np.int32, np.int16, np.int8)):
        return int(o)
    if isinstance(o, (np.float64, np.float32, np.float16)):
        return float(o)
    if isinstance(o, np.ndarray):
        return o.tolist()
    if isinstance(o, dict):
        return {k: convert_numpy_types(v) for k, v in o.items()}
    if isinstance(o, list):
        return [convert_numpy_types(i) for i in o]
    return o


def _create_flat_alias_map(kb: dict) -> dict:
    alias_to_canonical = {}
    for section, topics in kb.items():
        for topic_name_raw, aliases in topics.items():
            canonical_name = topic_name_raw.replace('_', ' ')
            alias_to_canonical[canonical_name.lower()] = canonical_name
            for alias in aliases:
                alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical

AVAILABLE_TOPICS = list(set(_create_flat_alias_map(DICIONARIO_UNIFICADO_HIERARQUICO).values()))

def expand_search_terms(base_term: str, kb: dict) -> list[str]:
    base_term_lower = base_term.lower()
    expanded_terms = {base_term_lower}
    for section, topics in kb.items():
        for topic, aliases in topics.items():
            all_terms_in_group = {alias.lower() for alias in aliases} | {topic.lower().replace('_', ' ')}
            if base_term_lower in all_terms_in_group:
                expanded_terms.update(all_terms_in_group)
    return list(expanded_terms)

def anonimizar_resultados(data, company_catalog, anom_map=None):
    """
    [VERSÃƒO CORRIGIDA E ROBUSTA] Recebe um DataFrame, texto ou dicionÃ¡rio e substitui
    os nomes das empresas e seus aliases por placeholders.
    Garante que a funÃ§Ã£o sempre retorne uma tupla (data, anom_map).
    """
    if anom_map is None:
        anom_map = {}

    # LÃ³gica para DataFrames
    if isinstance(data, pd.DataFrame):
        df_anonimizado = data.copy()
        target_col = None
        for col in df_anonimizado.columns:
            if 'empresa' in col.lower() or 'companhia' in col.lower():
                target_col = col
                break
        if target_col:
            def get_anon_name(company_name):
                if company_name not in anom_map:
                    company_info = next((item for item in company_catalog if item["canonical_name"] == company_name), None)
                    anon_name = f"Empresa {chr(65 + len(anom_map))}"
                    anom_map[company_name] = {
                        "anon_name": anon_name,
                        "aliases_to_replace": [company_name] + (company_info['aliases'] if company_info else [])
                    }
                return anom_map[company_name]["anon_name"]
            df_anonimizado[target_col] = df_anonimizado[target_col].apply(get_anon_name)
        return df_anonimizado, anom_map

    # LÃ³gica para DicionÃ¡rios de DataFrames
    if isinstance(data, dict):
        dict_anonimizado = {}
        for key, df in data.items():
            if isinstance(df, pd.DataFrame):
                dict_anonimizado[key], anom_map = anonimizar_resultados(df, company_catalog, anom_map)
            else:
                dict_anonimizado[key] = df
        return dict_anonimizado, anom_map
        
    # LÃ³gica para Texto (Garante o retorno)
    if isinstance(data, str):
        texto_anonimizado = data
        if anom_map:  # Apenas tenta substituir se o mapa nÃ£o estiver vazio
            for original_canonical, mapping in anom_map.items():
                anon_name = mapping["anon_name"]
                aliases_sorted = sorted(mapping["aliases_to_replace"], key=len, reverse=True)
                for alias in aliases_sorted:
                    pattern = r'(?<!\w)' + re.escape(alias) + r'(?!\w)'
                    texto_anonimizado = re.sub(pattern, anon_name, texto_anonimizado, flags=re.IGNORECASE)
        # SEMPRE retorna uma tupla, mesmo que o texto nÃ£o tenha sido alterado
        return texto_anonimizado, anom_map
        
    # Fallback para qualquer outro tipo de dado nÃ£o tratado
    return data, anom_map

def search_by_tags(query: str, kb: dict) -> list[str]:
    """
    VersÃ£o melhorada que busca por palavras-chave na query e retorna as tags correspondentes.
    Evita o uso de expressÃµes regulares complexas para cada chunk.
    """
    found_tags = set()
    # Converte a query para minÃºsculas e remove pontuaÃ§Ã£o para uma busca mais limpa
    clean_query = query.lower().strip()
    
    # Itera sobre todas as tags e seus sinÃ´nimos no dicionÃ¡rio de conhecimento
    for tag, details in kb.items():
        search_terms = [tag.lower()] + [s.lower() for s in details.get("sinonimos", [])]
        
        # Se qualquer um dos termos de busca estiver na query, adiciona a tag
        if any(term in clean_query for term in search_terms):
            found_tags.add(tag)
            
    return list(found_tags)

def get_final_unified_answer(query: str, context: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    has_complete_8_4 = "formulÃ¡rio de referÃªncia" in query.lower() and "8.4" in query.lower()
    has_tagged_chunks = "--- CONTEÃšDO RELEVANTE" in context
    structure_instruction = "Organize a resposta de forma lÃ³gica e clara usando Markdown."
    if has_complete_8_4:
        structure_instruction = "ESTRUTURA OBRIGATÃ“RIA PARA ITEM 8.4: Use a estrutura oficial do item 8.4 do FormulÃ¡rio de ReferÃªncia (a, b, c...)."
    elif has_tagged_chunks:
        structure_instruction = "PRIORIZE as informaÃ§Ãµes dos chunks recuperados e organize a resposta de forma lÃ³gica."
    prompt = f"""VocÃª Ã© um consultor especialista em planos de incentivo de longo prazo (ILP).
    PERGUNTA ORIGINAL DO USUÃRIO: "{query}"
    CONTEXTO COLETADO DOS DOCUMENTOS:
    {context}
    {structure_instruction}
    INSTRUÃ‡Ã•ES PARA O RELATÃ“RIO FINAL:
    1. Responda diretamente Ã  pergunta do usuÃ¡rio com base no contexto fornecido.
    2. Seja detalhado, preciso e profissional na sua linguagem. Use formataÃ§Ã£o Markdown.
    3. Se uma informaÃ§Ã£o especÃ­fica pedida nÃ£o estiver no contexto, declare explicitamente: "InformaÃ§Ã£o nÃ£o encontrada nas fontes analisadas.". NÃ£o invente dados.
    RELATÃ“RIO ANALÃTICO FINAL:"""
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        logger.error(f"ERRO ao gerar resposta final com LLM: {e}")
        return f"Ocorreu um erro ao contatar o modelo de linguagem. Detalhes: {str(e)}"

# <<< MELHORIA 1 ADICIONADA >>>
def get_query__with_llm(query: str) -> str:
    """
    Usa um LLM para classificar a intenÃ§Ã£o do usuÃ¡rio em 'quantitativa' ou 'qualitativa'.
    Retorna 'qualitativa' como padrÃ£o em caso de erro.
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"""
    Analise a pergunta do usuÃ¡rio e classifique a sua intenÃ§Ã£o principal. Responda APENAS com uma Ãºnica palavra em JSON.
    
    As opÃ§Ãµes de classificaÃ§Ã£o sÃ£o:
    1. "quantitativa": Se a pergunta busca por nÃºmeros, listas diretas, contagens, mÃ©dias, estatÃ­sticas ou agregaÃ§Ãµes. 
       Exemplos: "Quantas empresas tÃªm TSR Relativo?", "Qual a mÃ©dia de vesting?", "Liste as empresas com desconto no strike.".
    2. "qualitativa": Se a pergunta busca por explicaÃ§Ãµes, detalhes, comparaÃ§Ãµes, descriÃ§Ãµes ou anÃ¡lises aprofundadas.
       Exemplos: "Como funciona o plano da Vale?", "Compare os planos da Hypera e Movida.", "Detalhe o tratamento de dividendos.".

    Pergunta do UsuÃ¡rio: "{query}"

    Responda apenas com o JSON da classificaÃ§Ã£o. Exemplo de resposta: {{"": "qualitativa"}}
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.0,
            "maxOutputTokens": 50
        }
    }
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        response.raise_for_status()
        
        response_text = response.json()['candidates'][0]['content']['parts'][0]['text']
        # Corrigido: renomeado para intent_json para clareza
        intent_json = json.loads(re.search(r'\{.*\}', response_text, re.DOTALL).group())
        # Corrigido: Adicionada a variÃ¡vel 'intent' e a chave correta 'intent' no .get()
        intent = intent_json.get("intent", "qualitativa").lower()
        
        # Corrigido: Adicionada a variÃ¡vel 'intent' ao log
        logger.info(f"IntenÃ§Ã£o detectada pelo LLM: '{intent}' para a pergunta: '{query}'")
        
        # Corrigido: Adicionada a variÃ¡vel 'intent' na condiÃ§Ã£o
        if intent in ["quantitativa", "qualitativa"]:
            return intent
        else:
            logger.warning(f"IntenÃ§Ã£o nÃ£o reconhecida '{intent}'. Usando 'qualitativa' como padrÃ£o.")
            return "qualitativa"

    except Exception as e:
        logger.error(f"ERRO ao determinar intenÃ§Ã£o com LLM: {e}. Usando 'qualitativa' como padrÃ£o.")
        return "qualitativa"

# O restante do seu cÃ³digo pode seguir aqui...

from datetime import datetime # Certifique-se que 'datetime' estÃ¡ importado no topo do seu script

def execute_dynamic_plan(
    query: str,
    plan: dict,
    artifacts: dict,
    model,  # SentenceTransformer
    cross_encoder_model,  # CrossEncoder
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    search_by_tags: callable,
    expand_search_terms: callable,
    prioritize_recency: bool = True,
) -> tuple[str, list[dict]]:
    """
    VersÃ£o Completa de execute_dynamic_plan
    """

    import re
    import random
    from collections import defaultdict
    from datetime import datetime
    import faiss


    # -------------- HELPERS --------------
    def _is_company_match(plan_canonical_name: str, metadata_name: str) -> bool:
        if not plan_canonical_name or not metadata_name:
            return False

        # FunÃ§Ã£o auxiliar para remover acentos e caracteres especiais
        def normalize_text(text: str) -> str:
            import unicodedata
            import re
            # Remove acentos (diacrÃ­ticos)
            nfkd_form = unicodedata.normalize('NFKD', text.lower())
            only_ascii = nfkd_form.encode('ASCII', 'ignore').decode('utf-8')
            # Remove pontuaÃ§Ãµes e excesso de espaÃ§os
            only_ascii = re.sub(r'[^\w\s]', '', only_ascii)
            return ' '.join(only_ascii.split())

        normalized_plan_name = normalize_text(plan_canonical_name)
        normalized_metadata_name = normalize_text(metadata_name)

        return normalized_plan_name in normalized_metadata_name

    candidate_chunks_dict = {}

    def add_candidate(chunk):
        """Add chunk de forma Ãºnica por sua origem e id/texto."""
        key = chunk.get('source_url', '') + str(chunk.get('chunk_id', hash(chunk.get('text', ''))))
        if key not in candidate_chunks_dict:
            candidate_chunks_dict[key] = chunk

    # -------------- LOG INICIAL --------------
    logger.info(f"Executando plano dinÃ¢mico para query: '{query}'")
    plan_type = plan.get("plan_type", "default")
    empresas = plan.get("empresas", [])
    topicos = plan.get("topicos", [])

    # -------------- CARREGAMENTO E NORMALIZAÃ‡ÃƒO DOS CHUNKS --------------
    all_chunks = [
        chunk_meta
        for artifact_data in artifacts.values()
        for chunk_meta in artifact_data.get('chunks', [])
    ]
    for chunk in all_chunks:
        if 'chunk_text' in chunk and 'text' not in chunk:
            chunk['text'] = chunk.pop('chunk_text')
        if 'doc_type' not in chunk:
            if 'frmExibirArquivoFRE' in chunk.get('source_url', ''):
                chunk['doc_type'] = 'item_8_4'
            else:
                chunk['doc_type'] = 'outros_documentos'
        # PrÃ©vias para busca rÃ¡pida nos tÃ³picos (pode expandir conforme necessidade)
        if "topics_in_chunk" not in chunk:
            chunk["topics_in_chunk"] = []

    # -------------- FILTROS ----------
    filtros = plan.get("filtros", {})

    pre_filtered_chunks = all_chunks
    if filtros.get('setor'):
        pre_filtered_chunks = [
            c for c in pre_filtered_chunks
            if c.get('setor', '').lower() == filtros['setor'].lower()
        ]
    if filtros.get('controle_acionario'):
        pre_filtered_chunks = [
            c for c in pre_filtered_chunks
            if c.get('controle_acionario', '').lower() == filtros['controle_acionario'].lower()
        ]
    logger.info(f"ApÃ³s prÃ©-filtragem, {len(pre_filtered_chunks)} chunks sÃ£o candidatos.")

    # -------------- EXPANSÃƒO DE TERMOS COM BASE NOS TÃ“PICOS DO PLANO ----------------
    # Esta abordagem Ã© mais robusta pois utiliza os tÃ³picos jÃ¡ identificados pelo planejador.
    if topicos:
        expanded_terms = {query.lower()}
        for topic_path in topicos:
            # Pega o alias mais especÃ­fico (a Ãºltima parte do caminho do tÃ³pico) para expandir a busca.
            # Ex: De "ParticipantesCondicoes,CondicaoSaida", extrai "CondicaoSaida".
            alias = topic_path.split(',')[-1].replace('_', ' ')
            expanded_terms.update(expand_search_terms(alias, kb))
        
        query_to_search = " ".join(list(expanded_terms))
        logger.info(f"Query expandida com base nos tÃ³picos do plano: '{query_to_search}'")
    else:
        logger.info("Nenhum tÃ³pico encontrado no plano. Usando query original.")
        query_to_search = query

    # -------------- ROTEAMENTO PRINCIPAL --------------
    if plan_type == "section_8_4" and empresas:
        # ROTA CORRIGIDA para "descreva item 8.4 vivara"
        canonical_name_from_plan = empresas[0]
        search_name = next(
            (
                e.get("search_alias", canonical_name_from_plan)
                for e in company_catalog_rich
                if e.get("canonical_name") == canonical_name_from_plan
            ),
            canonical_name_from_plan,
        )
        logger.info(f"ROTA ESPECIAL section_8_4: Usando nome de busca '{search_name}'.")

        # 1. Filtra para obter todos os chunks do item 8.4 da empresa.
        chunks_to_search = [
            c for c in pre_filtered_chunks
            if c.get('doc_type') == 'item_8_4' and _is_company_match(canonical_name_from_plan, c.get('company_name', ''))
        ]

        # 2. SE chunks foram encontrados, adiciona TODOS eles diretamente aos candidatos.
        if chunks_to_search:
            logger.info(f"Rota 'section_8_4': {len(chunks_to_search)} chunks encontrados para '{canonical_name_from_plan}'. Adicionando todos ao contexto.")
            for chunk in chunks_to_search:
                add_candidate(chunk)
        else:
            logger.warning(f"Rota 'section_8_4': Nenhum chunk do tipo 'item_8_4' foi encontrado para a empresa '{canonical_name_from_plan}'.")

    else:
        if not empresas and topicos:
            # ROTA GERAL: LÃ³gica original preservada.
            logger.info(f"ROTA Default (Geral): busca conceitual para tÃ³picos: {topicos}")
            sample_size = 100
            chunks_to_search = random.sample(
                pre_filtered_chunks,
                min(sample_size, len(pre_filtered_chunks))
            )
            if chunks_to_search:
                temp_embeddings = model.encode(
                    [c['text'] for c in chunks_to_search],
                    normalize_embeddings=True
                ).astype('float32')
                temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
                temp_index.add(temp_embeddings)
                for topico in topicos:
                    for term in expand_search_terms(topico, kb)[:3]:
                        search_query = f"explicaÃ§Ã£o detalhada sobre o conceito e funcionamento de {term}"
                        query_embedding = model.encode(
                            [search_query],
                            normalize_embeddings=True
                        ).astype('float32')
                        _, indices = temp_index.search(query_embedding, TOP_K_FINAL)
                        for idx in indices[0]:
                            if idx != -1:
                                add_candidate(chunks_to_search[idx])

        elif empresas and topicos:
            # ROTA HÃBRIDA: LÃ³gica original e robusta preservada.
            logger.info(f"ROTA HÃBRIDA: Empresas: {empresas}, TÃ³picos: {topicos}")
            target_topic_paths = plan.get("topicos", [])

            for empresa_canonica in empresas:
                chunks_for_company = [
                    c for c in pre_filtered_chunks
                    if _is_company_match(empresa_canonica, c.get('company_name', ''))
                ]
                if not chunks_for_company:
                    continue

                # DeduplicaÃ§Ã£o e recorte por data (recency)
                docs_by_url = defaultdict(list)
                for chunk in chunks_for_company:
                    docs_by_url[chunk.get('source_url')].append(chunk)
                MAX_DOCS_PER_COMPANY = 3
                if len(docs_by_url) > MAX_DOCS_PER_COMPANY:
                    sorted_urls = sorted(
                        docs_by_url.keys(),
                        key=lambda url: docs_by_url[url][0].get('document_date', '0000-00-00'),
                        reverse=True
                    )
                    latest_urls = sorted_urls[:MAX_DOCS_PER_COMPANY]
                    chunks_for_company = [chunk for url in latest_urls for chunk in docs_by_url[url]]
                    logger.info(f"Para '{empresa_canonica}', selecionando os {MAX_DOCS_PER_COMPANY} documentos mais recentes pela DATA REAL.")

                # Etapa 1: Busca por tags (precisÃ£o)
                logger.info(f"[{empresa_canonica}] Etapa 1: Busca por tags nos metadados...")
                for chunk in chunks_for_company:
                    if any(
                        target_path in path
                        for path in chunk.get("topics_in_chunk", [])
                        for target_path in target_topic_paths
                    ):
                        add_candidate(chunk)

                # Etapa 2: Busca vetorial semÃ¢ntica (abrangÃªncia)
                logger.info(f"[{empresa_canonica}] Etapa 2: Busca por similaridade semÃ¢ntica...")
                if chunks_for_company:
                    temp_embeddings = model.encode(
                        [c.get('text', '') for c in chunks_for_company],
                        normalize_embeddings=True
                    ).astype('float32')
                    temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
                    temp_index.add(temp_embeddings)
                    search_name = next(
                        (
                            e.get("search_alias", empresa_canonica)
                            for e in company_catalog_rich
                            if e.get("canonical_name") == empresa_canonica
                        ),
                        empresa_canonica
                    )
                    search_query = (f"informaÃ§Ãµes detalhadas sobre "
                                    f"{' e '.join(topicos)} no plano da empresa {search_name}")
                    query_embedding = model.encode(
                        [search_query], normalize_embeddings=True
                    ).astype('float32')
                    _, indices = temp_index.search(
                        query_embedding,
                        min(TOP_K_INITIAL_RETRIEVAL, len(chunks_for_company))
                    )
                    for idx in indices[0]:
                        if idx != -1:
                            add_candidate(chunks_for_company[idx])
    # -------------------- RE-RANKING FINAL ----------------------------
    if not candidate_chunks_dict:
        logger.warning(
            f"Nenhum chunk candidato encontrado para a query: '{query}' com os filtros aplicados."
        )
        return "NÃ£o encontrei informaÃ§Ãµes relevantes para esta combinaÃ§Ã£o especÃ­fica de consulta e filtros.", []

    candidate_list = list(candidate_chunks_dict.values())
    if prioritize_recency:
        logger.info("Re-ranking adicional por recÃªncia ativado.")
        candidate_list = rerank_by_recency(candidate_list, datetime.now())

    reranked_chunks = rerank_with_cross_encoder(
        query, candidate_list, cross_encoder_model, top_n=TOP_K_FINAL
    )

    # -------------- CONSTRUÃ‡ÃƒO DO CONTEXTO FINAL PARA RETORNO ---------------
    full_context = ""
    retrieved_sources = []
    seen_sources = set()
    for chunk in reranked_chunks:
        company_name = chunk.get('company_name', 'N/A')
        source_url = chunk.get('source_url', 'N/A')
        source_header = (
            f"(Empresa: {company_name}, Setor: {chunk.get('setor', 'N/A')}, "
            f"Documento: {chunk.get('doc_type', 'N/A')})"
        )
        clean_text = re.sub(r'\[.*?\]', '', chunk.get('text', '')).strip()
        full_context += (
            f"--- CONTEÃšDO RELEVANTE {source_header} ---\n{clean_text}\n\n"
        )
        source_tuple = (company_name, source_url)
        if source_tuple not in seen_sources:
            seen_sources.add(source_tuple)
            retrieved_sources.append(chunk)

    logger.info(
        f"Contexto final construÃ­do a partir de {len(reranked_chunks)} chunks re-ranqueados."
    )
    return full_context, retrieved_sources

    
def create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters: dict):
    """
    [VERSÃƒO DE DEPURAÃ‡ÃƒO] do planejador dinÃ¢mico para inspecionar a
    identificaÃ§Ã£o de tÃ³picos.
    """
    # Adicione 'import streamlit as st' no topo do seu arquivo, se ainda nÃ£o o fez.
    import streamlit as st

    
    logger.info(f"Gerando plano dinÃ¢mico v3.0 para a pergunta: '{query}'")
    query_lower = query.lower().strip()
    
    plan = {
        "empresas": [],
        "topicos": [],
        "filtros": filters.copy(),
        "plan_type": "default"
    }

    # A lÃ³gica de identificaÃ§Ã£o de empresas nÃ£o Ã© o foco do bug, entÃ£o a mantemos como estÃ¡.
    mentioned_companies = []
    if company_catalog_rich:
        companies_found_by_alias = {}
        for company_data in company_catalog_rich:
            canonical_name = company_data.get("canonical_name")
            if not canonical_name: continue
            
            all_aliases = company_data.get("aliases", []) + [canonical_name]
            for alias in all_aliases:
                if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                    score = len(alias.split())
                    if canonical_name not in companies_found_by_alias or score > companies_found_by_alias[canonical_name]:
                        companies_found_by_alias[canonical_name] = score
        if companies_found_by_alias:
            mentioned_companies = [c for c, s in sorted(companies_found_by_alias.items(), key=lambda item: item[1], reverse=True)]

    if not mentioned_companies:
        for empresa_nome in summary_data.keys():
            if re.search(r'\b' + re.escape(empresa_nome.lower()) + r'\b', query_lower):
                mentioned_companies.append(empresa_nome)
    
    plan["empresas"] = mentioned_companies
    logger.info(f"Empresas identificadas: {plan['empresas']}")

    
        
    # O resto da funÃ§Ã£o continua normalmente para que o app nÃ£o quebre
    if plan["empresas"] and not plan["topicos"]:
        logger.info("Nenhum tÃ³pico especÃ­fico encontrado. Ativando modo de resumo/comparaÃ§Ã£o geral.")
        plan["plan_type"] = "summary"
        plan["topicos"] = [
            "TiposDePlano", "ParticipantesCondicoes,Elegibilidade", "MecanicasCicloDeVida,Vesting", 
            "MecanicasCicloDeVida,Lockup", "IndicadoresPerformance", 
            "EventosFinanceiros,DividendosProventos"
        ]
        logger.info(f"TÃ³picos de resumo geral adicionados ao plano: {plan['topicos']}")    

    if not plan["empresas"] and not plan["topicos"] and not plan["filtros"]:
        logger.warning("Planejador nÃ£o conseguiu identificar empresa, tÃ³pico ou filtro na pergunta.")
        return {"status": "error", "message": "NÃ£o foi possÃ­vel identificar uma intenÃ§Ã£o clara na sua pergunta. Tente ser mais especÃ­fico."}
        
    return {"status": "success", "plan": plan}

    
def analyze_single_company(
    empresa: str,
    plan: dict,
    query: str,
    artifacts: dict,
    model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    execute_dynamic_plan_func: callable,
    get_final_unified_answer_func: callable
) -> dict:
    """
    Executa o plano de anÃ¡lise para uma Ãºnica empresa e retorna um dicionÃ¡rio estruturado.
    """
    single_plan = {'empresas': [empresa], 'topicos': plan['topicos']}
    
    context, sources_list = execute_dynamic_plan_func(query, single_plan, artifacts, model, cross_encoder_model, kb, company_catalog_rich,
        company_lookup_map, search_by_tags, expand_search_terms)
    
    result_data = {
        "empresa": empresa,
        "resumos_por_topico": {topico: "InformaÃ§Ã£o nÃ£o encontrada" for topico in plan['topicos']},
        "sources": sources_list
    }

    if context:
        summary_prompt = f"""
        Com base no CONTEXTO abaixo sobre a empresa {empresa}, crie um resumo para cada um dos TÃ“PICOS solicitados.
        Sua resposta deve ser APENAS um objeto JSON vÃ¡lido, sem nenhum texto adicional antes ou depois.
        
        TÃ“PICOS PARA RESUMIR: {json.dumps(plan['topicos'])}
        
        CONTEXTO:
        {context}
        
        FORMATO OBRIGATÃ“RIO DA RESPOSTA (APENAS JSON):
        {{
            "resumos_por_topico": {{
                "TÃ³pico 1": "Resumo conciso sobre o TÃ³pico 1...",
                "TÃ³pico 2": "Resumo conciso sobre o TÃ³pico 2...",
                "...": "..."
            }}
        }}
        """
        
        try:
            json_response_str = get_final_unified_answer_func(summary_prompt, context)
            json_match = re.search(r'\{.*\}', json_response_str, re.DOTALL)
            if json_match:
                parsed_json = json.loads(json_match.group())
                result_data["resumos_por_topico"] = parsed_json.get("resumos_por_topico", result_data["resumos_por_topico"])
            else:
                logger.warning(f"NÃ£o foi possÃ­vel extrair JSON da resposta para a empresa {empresa}.")

        except (json.JSONDecodeError, Exception) as e:
            logger.error(f"Erro ao processar o resumo JSON para {empresa}: {e}")
            
    return result_data


def handle_rag_query(
    query: str,
    artifacts: dict,
    embedding_model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    summary_data: dict,
    filters: dict,
    prioritize_recency: bool = False,
    anonimizar_empresas: bool = False
) -> tuple[str, list[dict]]:
    """
    [VERSÃƒO FINAL E CORRIGIDA] Orquestra o pipeline de RAG, aplicando a anonimizaÃ§Ã£o
    de forma centralizada e consistente em todos os fluxos.
    """
    with st.status("1ï¸âƒ£ Gerando plano de anÃ¡lise...", expanded=True) as status:
        plan_response = create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters)
        
        if plan_response['status'] != "success":
            status.update(label="âš ï¸ Falha na identificaÃ§Ã£o", state="error", expanded=True)
            st.warning("NÃ£o consegui identificar uma empresa ou tÃ³pico em sua pergunta.")
            # ... (cÃ³digo de sugestÃ£o de query) ...
            return "", []
            
        plan = plan_response['plan']
        mapa_anonimizacao = {}
        display_empresas = plan.get('empresas', [])

        # Etapa 1: AnonimizaÃ§Ã£o para a UI (cria o mapa inicial)
        if anonimizar_empresas and display_empresas:
            df_empresas_plano = pd.DataFrame([{"Empresa": e} for e in display_empresas])
            df_anon, mapa_anonimizacao = anonimizar_resultados(df_empresas_plano, st.session_state.company_catalog_rich)
            display_empresas = df_anon["Empresa"].tolist()

        if display_empresas:
            st.write(f"**ğŸ¢ Empresas identificadas:** {', '.join(display_empresas)}")
        else:
            st.write("**ğŸ¢ Nenhuma empresa especÃ­fica identificada. Realizando busca geral.**")
            
        st.write(f"**ğŸ“ TÃ³picos a analisar:** {', '.join(plan['topicos'])}")
        status.update(label="âœ… Plano gerado com sucesso!", state="complete")

    final_answer, all_sources_structured = "", []
    
    # --- LÃ³gica para MÃºltiplas Empresas (ComparaÃ§Ã£o) ---
    if len(plan.get('empresas', [])) > 1:
        st.info(f"Modo de comparaÃ§Ã£o ativado para {len(plan['empresas'])} empresas...")
        
        with st.spinner(f"Analisando {len(plan['empresas'])} empresas..."):
            # ... (cÃ³digo do ThreadPoolExecutor para coletar 'results') ...
            with ThreadPoolExecutor(max_workers=len(plan['empresas'])) as executor:
                futures = [
                    executor.submit(
                        analyze_single_company, empresa, plan, query, artifacts, embedding_model, cross_encoder_model, 
                        kb, company_catalog_rich, company_lookup_map, execute_dynamic_plan, get_final_unified_answer) 
                    for empresa in plan['empresas']
                ]
                results = [future.result() for future in futures]
        
        results = convert_numpy_types(results)

        # Etapa 2: AnonimizaÃ§Ã£o do CONTEÃšDO para o LLM
        if anonimizar_empresas:
            # Primeiro, anonimiza os resultados da anÃ¡lise, reutilizando e atualizando o mapa
            for res in results:
                res['empresa'], mapa_anonimizacao = anonimizar_resultados(res['empresa'], st.session_state.company_catalog_rich, mapa_anonimizacao)
                for topico, resumo in res['resumos_por_topico'].items():
                    res['resumos_por_topico'][topico], mapa_anonimizacao = anonimizar_resultados(resumo, st.session_state.company_catalog_rich, mapa_anonimizacao)

            # Depois, anonimiza a lista de fontes usando o MESMO mapa
            sources_list = [src for res in results for src in res.get('sources', [])]
            df_sources = pd.DataFrame(sources_list)
            if not df_sources.empty:
                df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)
                df_sources_anon, _ = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)
                all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')

        else: # Se nÃ£o estiver anonimizando, apenas coleta as fontes
            all_sources_structured = [src for res in results for src in res.get('sources', [])]


        with st.status("Gerando relatÃ³rio comparativo final...", expanded=True) as status:
            structured_context = json.dumps(results, indent=2, ensure_ascii=False)
            comparison_prompt = f"""
            Sua tarefa Ã© criar um relatÃ³rio comparativo sobre "{query}" usando o CONTEXTO JSON abaixo.
            Os nomes das empresas jÃ¡ foram anonimizados. Use apenas os nomes anonimizados (ex: "Empresa A", "Empresa B") na sua resposta.
            Crie uma breve anÃ¡lise textual seguida por uma TABELA MARKDOWN clara e bem formatada.

            CONTEXTO:
            {structured_context}
            """
            final_answer = get_final_unified_answer(comparison_prompt, structured_context)
            status.update(label="âœ… RelatÃ³rio comparativo gerado!", state="complete")
            
    # --- LÃ³gica para Empresa Ãšnica ou Busca Geral ---
    else:
        # ... (cÃ³digo idÃªntico ao da resposta anterior, que jÃ¡ estÃ¡ correto)
        with st.status("2ï¸âƒ£ Recuperando e re-ranqueando contexto...", expanded=True) as status:
            context, all_sources_structured = execute_dynamic_plan(
                query, plan, artifacts, embedding_model, cross_encoder_model, kb, company_catalog_rich, company_lookup_map, search_by_tags, expand_search_terms)
            
            if not context:
                st.error("âŒ NÃ£o encontrei informaÃ§Ãµes relevantes nos documentos para a sua consulta.")
                return "Nenhuma informaÃ§Ã£o relevante encontrada.", []
                
            st.write(f"**ğŸ“„ Contexto recuperado de:** {len(all_sources_structured)} documento(s)")
            status.update(label="âœ… Contexto relevante selecionado!", state="complete")
        
        if anonimizar_empresas:
            df_sources = pd.DataFrame(all_sources_structured)
            if not df_sources.empty:
                df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)
                # Usa o mapa inicial (se houver) e o atualiza
                df_sources_anon, mapa_anonimizacao = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)
                all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')
            
            context, _ = anonimizar_resultados(context, st.session_state.company_catalog_rich, mapa_anonimizacao)
            
        with st.status("3ï¸âƒ£ Gerando resposta final...", expanded=True) as status:
            prompt_final = f"""
            Responda Ã  pergunta: "{query}".
            Use o contexto abaixo, que jÃ¡ estÃ¡ anonimizado. Refira-se Ã  empresa principal como "a Empresa" ou "a Companhia".
            CONTEXTO: {context}
            """
            final_answer = get_final_unified_answer(prompt_final, context)
            status.update(label="âœ… AnÃ¡lise concluÃ­da!", state="complete")

    # Remove duplicatas das fontes coletadas
    unique_sources = list({v['source_url']:v for v in all_sources_structured}.values())
    return final_answer, unique_sources
Principais MudanÃ§as na LÃ³gica de ComparaÃ§Ã£o
Mapa de AnonimizaÃ§Ã£o Centralizado: A variÃ¡vel mapa_anonimizacao Ã© criada no inÃ­cio. Quando o modo de anonimizaÃ§Ã£o estÃ¡ ativo, ela Ã© passada para a primeira chamada de anonimizar_resultados (que anonimiza os nomes para a UI) e depois Ã© reutilizada e atualizada ao anonimizar os resultados da anÃ¡lise e a lista de fontes. Isso garante que "Empresa B" seja sempre "Empresa B", resolvendo o bug de "Empresa C".

Prompt do LLM Simplificado: O prompt agora instrui o Gemini a usar apenas os nomes anonimizados que ele recebe no JSON, eliminando a confusÃ£o e a geraÃ§Ã£o de textos como "Empresa A (Empresa A Branco)".

Coleta de Fontes Simplificada: A lÃ³gica para coletar e remover duplicatas das fontes foi otimizada.

Com essas alteraÃ§Ãµes, o sistema agora deve anonimizar os nomes de forma consistente em todo o relatÃ³rio de comparaÃ§Ã£o. AgradeÃ§o imensamente pela sua ajuda em depurar e aprimorar o agente!







preciso da funÃ§Ã£o inteira sem simplficaÃ§Ãµes ou omissÃµes ajustada

def handle_rag_query(

Â  Â  query: str,

Â  Â  artifacts: dict,

Â  Â  embedding_model: SentenceTransformer,

Â  Â  cross_encoder_model: CrossEncoder,

Â  Â  kb: dict,

Â  Â  company_catalog_rich: list,

Â  Â  company_lookup_map: dict,

Â  Â  summary_data: dict,

Â  Â  filters: dict,

Â  Â  prioritize_recency: bool = False,

Â  Â  anonimizar_empresas: bool = FalseÂ  # Adicionado o parÃ¢metro aqui

) -> tuple[str, list[dict]]:

Â  Â  """

Â  Â  [VERSÃƒO CORRIGIDA] Orquestra o pipeline de RAG, aplicando a anonimizaÃ§Ã£o

Â  Â  corretamente tanto para a UI quanto para o contexto do LLM.

Â  Â  """

Â  Â  with st.status("1ï¸âƒ£ Gerando plano de anÃ¡lise...", expanded=True) as status:

Â  Â  Â  Â  plan_response = create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters)

Â  Â  Â  Â Â 

Â  Â  Â  Â  if plan_response['status'] != "success":

Â  Â  Â  Â  Â  Â  status.update(label="âš ï¸ Falha na identificaÃ§Ã£o", state="error", expanded=True)

Â  Â  Â  Â  Â  Â  st.warning("NÃ£o consegui identificar uma empresa conhecida na sua pergunta para realizar uma anÃ¡lise profunda.")

Â  Â  Â  Â  Â  Â  with st.spinner("Estou pensando em uma pergunta alternativa..."):

Â  Â  Â  Â  Â  Â  Â  Â  alternative_query = suggest_alternative_query(query, kb)

Â  Â  Â  Â  Â  Â  st.markdown("#### Que tal tentar uma pergunta mais geral?")

Â  Â  Â  Â  Â  Â  st.code(alternative_query, language=None)

Â  Â  Â  Â  Â  Â  return "", []

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  plan = plan_response['plan']

Â  Â  Â  Â  mapa_anonimizacao = {}

Â  Â  Â  Â  display_empresas = plan['empresas']



Â  Â  Â  Â  # Etapa 1: AnonimizaÃ§Ã£o para a UI (antes de exibir qualquer coisa)

Â  Â  Â  Â  if anonimizar_empresas and plan.get('empresas'):

Â  Â  Â  Â  Â  Â  df_empresas_plano = pd.DataFrame([{"Empresa": e} for e in plan['empresas']])

Â  Â  Â  Â  Â  Â  df_anon, mapa_anonimizacao = anonimizar_resultados(df_empresas_plano, st.session_state.company_catalog_rich)

Â  Â  Â  Â  Â  Â  display_empresas = df_anon["Empresa"].tolist()



Â  Â  Â  Â  if display_empresas:

Â  Â  Â  Â  Â  Â  st.write(f"**ğŸ¢ Empresas identificadas:** {', '.join(display_empresas)}")

Â  Â  Â  Â  else:

Â  Â  Â  Â  Â  Â  st.write("**ğŸ¢ Nenhuma empresa especÃ­fica identificada. Realizando busca geral.**")

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  st.write(f"**ğŸ“ TÃ³picos a analisar:** {', '.join(plan['topicos'])}")

Â  Â  Â  Â  status.update(label="âœ… Plano gerado com sucesso!", state="complete")



Â  Â  final_answer, all_sources_structured = "", []

Â  Â  seen_sources_tuples = set()



Â  Â  # --- LÃ³gica para MÃºltiplas Empresas (ComparaÃ§Ã£o) ---

Â  Â  if len(plan.get('empresas', [])) > 1:

Â  Â  Â  Â  st.info(f"Modo de comparaÃ§Ã£o ativado para {len(plan['empresas'])} empresas. Executando anÃ¡lises em paralelo...")

Â  Â  Â  Â Â 

Â  Â  Â  Â  with st.spinner(f"Analisando {len(plan['empresas'])} empresas..."):

Â  Â  Â  Â  Â  Â  with ThreadPoolExecutor(max_workers=len(plan['empresas'])) as executor:

Â  Â  Â  Â  Â  Â  Â  Â  futures = [

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  executor.submit(

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  analyze_single_company, empresa, plan, query, artifacts, embedding_model, cross_encoder_model,Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  kb, company_catalog_rich, company_lookup_map, execute_dynamic_plan, get_final_unified_answer)Â 

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for empresa in plan['empresas']

Â  Â  Â  Â  Â  Â  Â  Â  ]

Â  Â  Â  Â  Â  Â  Â  Â  results = [future.result() for future in futures]



Â  Â  Â  Â  # Coleta todas as fontes primeiro para anonimizaÃ§Ã£o consistente

Â  Â  Â  Â  results = convert_numpy_types(results)

Â  Â  Â  Â  for result in results:

Â  Â  Â  Â  Â  Â  for src_dict in result.get('sources', []):

Â  Â  Â  Â  Â  Â  Â  Â  src_tuple = (src_dict.get('company_name'), src_dict.get('source_url'))

Â  Â  Â  Â  Â  Â  Â  Â  if src_tuple not in seen_sources_tuples:

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  seen_sources_tuples.add(src_tuple)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  all_sources_structured.append(src_dict)

Â  Â  Â  Â Â 

Â  Â  Â  Â  # Etapa 2: AnonimizaÃ§Ã£o do CONTEÃšDO para o LLM

Â  Â  Â  Â  if anonimizar_empresas:

Â  Â  Â  Â  Â  Â  # Anonimiza a lista de fontes

Â  Â  Â  Â  Â  Â  df_sources = pd.DataFrame(all_sources_structured)

Â  Â  Â  Â  Â  Â  if not df_sources.empty:

Â  Â  Â  Â  Â  Â  Â  Â  df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)

Â  Â  Â  Â  Â  Â  Â  Â  df_sources_anon, mapa_anonimizacao_fontes = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)

Â  Â  Â  Â  Â  Â  Â  Â  all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Anonimiza os resultados da anÃ¡lise que serÃ£o enviados ao LLM

Â  Â  Â  Â  Â  Â  for res in results:

Â  Â  Â  Â  Â  Â  Â  Â  # Substitui o nome da empresa pelo nome anonimizado do mapa

Â  Â  Â  Â  Â  Â  Â  Â  res['empresa'], _ = anonimizar_resultados(res['empresa'], st.session_state.company_catalog_rich, mapa_anonimizacao)

Â  Â  Â  Â  Â  Â  Â  Â  # Substitui os nomes dentro dos textos de resumo

Â  Â  Â  Â  Â  Â  Â  Â  for topico, resumo in res['resumos_por_topico'].items():

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  res['resumos_por_topico'][topico], _ = anonimizar_resultados(resumo, st.session_state.company_catalog_rich, mapa_anonimizacao)



Â  Â  Â  Â  with st.status("Gerando relatÃ³rio comparativo final...", expanded=True) as status:

Â  Â  Â  Â  Â  Â  structured_context = json.dumps(results, indent=2, ensure_ascii=False)

Â  Â  Â  Â  Â  Â  comparison_prompt = f"""

Â  Â  Â  Â  Â  Â  Sua tarefa Ã© criar um relatÃ³rio comparativo detalhado sobre "{query}".

Â  Â  Â  Â  Â  Â  Use os dados estruturados fornecidos no CONTEXTO JSON abaixo. Os nomes das empresas jÃ¡ foram anonimizados para "Empresa A", "Empresa B", etc. Use esses nomes anonimizados na sua resposta.

Â  Â  Â  Â  Â  Â  O relatÃ³rio deve comeÃ§ar com uma breve anÃ¡lise textual e, em seguida, apresentar uma TABELA MARKDOWN clara e bem formatada.



Â  Â  Â  Â  Â  Â  CONTEXTO (em formato JSON):

Â  Â  Â  Â  Â  Â  {structured_context}

Â  Â  Â  Â  Â  Â  """

Â  Â  Â  Â  Â  Â  final_answer = get_final_unified_answer(comparison_prompt, structured_context)

Â  Â  Â  Â  Â  Â  status.update(label="âœ… RelatÃ³rio comparativo gerado!", state="complete")

Â  Â  Â  Â  Â  Â Â 

Â  Â  # --- LÃ³gica para Empresa Ãšnica ou Busca Geral ---

Â  Â  else:

Â  Â  Â  Â  with st.status("2ï¸âƒ£ Recuperando e re-ranqueando contexto...", expanded=True) as status:

Â  Â  Â  Â  Â  Â  context, all_sources_structured = execute_dynamic_plan(

Â  Â  Â  Â  Â  Â  Â  Â  query, plan, artifacts, embedding_model, cross_encoder_model, kb, company_catalog_rich, company_lookup_map, search_by_tags, expand_search_terms)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  if not context:

Â  Â  Â  Â  Â  Â  Â  Â  st.error("âŒ NÃ£o encontrei informaÃ§Ãµes relevantes nos documentos para a sua consulta.")

Â  Â  Â  Â  Â  Â  Â  Â  return "Nenhuma informaÃ§Ã£o relevante encontrada.", []

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  st.write(f"**ğŸ“„ Contexto recuperado de:** {len(all_sources_structured)} documento(s)")

Â  Â  Â  Â  Â  Â  status.update(label="âœ… Contexto relevante selecionado!", state="complete")

Â  Â  Â  Â Â 

Â  Â  Â  Â  # Etapa 2: AnonimizaÃ§Ã£o do CONTEÃšDO para o LLM

Â  Â  Â  Â  if anonimizar_empresas:

Â  Â  Â  Â  Â  Â  # Garante que o mapa estÃ¡ populado com as fontes

Â  Â  Â  Â  Â  Â  df_sources = pd.DataFrame(all_sources_structured)

Â  Â  Â  Â  Â  Â  if not df_sources.empty:

Â  Â  Â  Â  Â  Â  Â  Â  df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)

Â  Â  Â  Â  Â  Â  Â  Â  df_sources_anon, mapa_anonimizacao = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)

Â  Â  Â  Â  Â  Â  Â  Â  all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  Â  Â  # Anonimiza o texto do contexto usando o mapa populado

Â  Â  Â  Â  Â  Â  context, _ = anonimizar_resultados(context, st.session_state.company_catalog_rich, mapa_anonimizacao)

Â  Â  Â  Â  Â  Â Â 

Â  Â  Â  Â  with st.status("3ï¸âƒ£ Gerando resposta final...", expanded=True) as status:

Â  Â  Â  Â  Â  Â  prompt_final = f"""

Â  Â  Â  Â  Â  Â  Responda Ã  pergunta: "{query}".

Â  Â  Â  Â  Â  Â  Use o contexto abaixo, que jÃ¡ estÃ¡ anonimizado. Refira-se Ã  empresa principal como "a Empresa" ou "a Companhia". NÃ£o tente adivinhar o nome original.



Â  Â  Â  Â  Â  Â  CONTEXTO:

Â  Â  Â  Â  Â  Â  {context}

Â  Â  Â  Â  Â  Â  """

Â  Â  Â  Â  Â  Â  final_answer = get_final_unified_answer(prompt_final, context)

Â  Â  Â  Â  Â  Â  status.update(label="âœ… AnÃ¡lise concluÃ­da!", state="complete")



Â  Â  return final_answer, all_sources_structured




Mostrar raciocÃ­nio
Compreendi. VocÃª precisa da funÃ§Ã£o handle_rag_query completa, com todos os ajustes de anonimizaÃ§Ã£o para os modos de empresa Ãºnica e de comparaÃ§Ã£o, sem nenhuma simplificaÃ§Ã£o.

PeÃ§o desculpas pela confusÃ£o anterior. O erro de lÃ³gica na passagem do mapa_anonimizacao causou as inconsistÃªncias. Abaixo estÃ¡ a versÃ£o integral e corrigida da funÃ§Ã£o, que vocÃª pode substituir em seu arquivo app.py.

Esta versÃ£o garante que:

Um Ãºnico mapa de anonimizaÃ§Ã£o Ã© criado e reutilizado em todas as etapas (UI, anÃ¡lise de resultados e lista de fontes), garantindo consistÃªncia nos nomes ("Empresa A", "Empresa B", etc.).

O contexto enviado ao LLM (tanto o texto quanto o JSON) jÃ¡ estÃ¡ prÃ©-anonimizado, evitando que ele "vaze" nomes reais.

O prompt para o LLM Ã© claro e instrui o modelo a usar apenas os nomes anonimizados fornecidos.

FunÃ§Ã£o handle_rag_query Completa e Corrigida
Python

def handle_rag_query(
    query: str,
    artifacts: dict,
    embedding_model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    summary_data: dict,
    filters: dict,
    prioritize_recency: bool = False,
    anonimizar_empresas: bool = False
) -> tuple[str, list[dict]]:
    """
    [VERSÃƒO COMPLETA E CORRIGIDA] Orquestra o pipeline de RAG, aplicando a anonimizaÃ§Ã£o
    de forma centralizada e consistente em todos os fluxos.
    """
    with st.status("1ï¸âƒ£ Gerando plano de anÃ¡lise...", expanded=True) as status:
        plan_response = create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters)
        
        if plan_response['status'] != "success":
            status.update(label="âš ï¸ Falha na identificaÃ§Ã£o", state="error", expanded=True)
            st.warning("NÃ£o consegui identificar uma empresa conhecida na sua pergunta para realizar uma anÃ¡lise profunda.")
            with st.spinner("Estou pensando em uma pergunta alternativa..."):
                alternative_query = suggest_alternative_query(query, kb)
            st.markdown("#### Que tal tentar uma pergunta mais geral?")
            st.code(alternative_query, language=None)
            return "", []
            
        plan = plan_response['plan']
        mapa_anonimizacao = {}
        display_empresas = plan.get('empresas', [])

        # Etapa 1: AnonimizaÃ§Ã£o para a UI (cria o mapa inicial e consistente)
        if anonimizar_empresas and display_empresas:
            df_empresas_plano = pd.DataFrame([{"Empresa": e} for e in display_empresas])
            df_anon, mapa_anonimizacao = anonimizar_resultados(df_empresas_plano, st.session_state.company_catalog_rich, mapa_anonimizacao)
            display_empresas = df_anon["Empresa"].tolist()

        if display_empresas:
            st.write(f"**ğŸ¢ Empresas identificadas:** {', '.join(display_empresas)}")
        else:
            st.write("**ğŸ¢ Nenhuma empresa especÃ­fica identificada. Realizando busca geral.**")
            
        st.write(f"**ğŸ“ TÃ³picos a analisar:** {', '.join(plan['topicos'])}")
        status.update(label="âœ… Plano gerado com sucesso!", state="complete")

    final_answer = ""
    all_sources_structured = []

    # --- LÃ³gica para MÃºltiplas Empresas (ComparaÃ§Ã£o) ---
    if len(plan.get('empresas', [])) > 1:
        st.info(f"Modo de comparaÃ§Ã£o ativado para {len(plan['empresas'])} empresas. Executando anÃ¡lises em paralelo...")
        
        with st.spinner(f"Analisando {len(plan['empresas'])} empresas..."):
            with ThreadPoolExecutor(max_workers=len(plan['empresas'])) as executor:
                futures = [
                    executor.submit(
                        analyze_single_company, empresa, plan, query, artifacts, embedding_model, cross_encoder_model, 
                        kb, company_catalog_rich, company_lookup_map, execute_dynamic_plan, get_final_unified_answer) 
                    for empresa in plan['empresas']
                ]
                results = [future.result() for future in futures]
        
        results = convert_numpy_types(results)

        # Etapa 2: AnonimizaÃ§Ã£o do CONTEÃšDO para o LLM
        if anonimizar_empresas:
            # Primeiro, anonimiza os resultados da anÃ¡lise, reutilizando e atualizando o mapa
            for res in results:
                res['empresa'], mapa_anonimizacao = anonimizar_resultados(res['empresa'], st.session_state.company_catalog_rich, mapa_anonimizacao)
                for topico, resumo in res['resumos_por_topico'].items():
                    res['resumos_por_topico'][topico], mapa_anonimizacao = anonimizar_resultados(resumo, st.session_state.company_catalog_rich, mapa_anonimizacao)

            # Depois, anonimiza a lista de fontes usando o MESMO mapa consistente
            sources_list = [src for res in results for src in res.get('sources', [])]
            df_sources = pd.DataFrame(sources_list)
            if not df_sources.empty:
                df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)
                df_sources_anon, _ = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)
                all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')

        else: # Se nÃ£o estiver anonimizando, apenas coleta as fontes
            all_sources_structured = [src for res in results for src in res.get('sources', [])]

        with st.status("Gerando relatÃ³rio comparativo final...", expanded=True) as status:
            structured_context = json.dumps(results, indent=2, ensure_ascii=False)
            comparison_prompt = f"""
            Sua tarefa Ã© criar um relatÃ³rio comparativo detalhado sobre "{query}" usando o CONTEXTO JSON abaixo.
            Os nomes das empresas no contexto jÃ¡ foram anonimizados para "Empresa A", "Empresa B", etc. Use apenas estes nomes anonimizados na sua resposta para garantir a confidencialidade.
            O relatÃ³rio deve comeÃ§ar com uma breve anÃ¡lise textual e, em seguida, apresentar uma TABELA MARKDOWN clara e bem formatada.

            CONTEXTO (em formato JSON):
            {structured_context}
            """
            final_answer = get_final_unified_answer(comparison_prompt, structured_context)
            status.update(label="âœ… RelatÃ³rio comparativo gerado!", state="complete")
            
    # --- LÃ³gica para Empresa Ãšnica ou Busca Geral ---
    else:
        with st.status("2ï¸âƒ£ Recuperando e re-ranqueando contexto...", expanded=True) as status:
            context, sources_from_plan = execute_dynamic_plan(
                query, plan, artifacts, embedding_model, cross_encoder_model, kb, company_catalog_rich, company_lookup_map, search_by_tags, expand_search_terms, prioritize_recency=prioritize_recency)
            
            if not context:
                st.error("âŒ NÃ£o encontrei informaÃ§Ãµes relevantes nos documentos para a sua consulta.")
                return "Nenhuma informaÃ§Ã£o relevante encontrada.", []
            
            all_sources_structured = sources_from_plan
            st.write(f"**ğŸ“„ Contexto recuperado de:** {len(all_sources_structured)} documento(s)")
            status.update(label="âœ… Contexto relevante selecionado!", state="complete")
        
        # Etapa 2: AnonimizaÃ§Ã£o do CONTEÃšDO para o LLM
        if anonimizar_empresas:
            # Garante que o mapa estÃ¡ populado com as fontes
            df_sources = pd.DataFrame(all_sources_structured)
            if not df_sources.empty:
                df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)
                df_sources_anon, mapa_anonimizacao = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich, mapa_anonimizacao)
                all_sources_structured = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')
            
            # Anonimiza o texto do contexto usando o mapa jÃ¡ populado
            context, _ = anonimizar_resultados(context, st.session_state.company_catalog_rich, mapa_anonimizacao)
            
        with st.status("3ï¸âƒ£ Gerando resposta final...", expanded=True) as status:
            prompt_final = f"""
            Responda Ã  pergunta: "{query}".
            Use o contexto abaixo, que jÃ¡ estÃ¡ anonimizado. Refira-se Ã  empresa principal como "a Empresa" ou "a Companhia". NÃ£o tente adivinhar o nome original.

            CONTEXTO:
            {context}
            """
            final_answer = get_final_unified_answer(prompt_final, context)
            status.update(label="âœ… AnÃ¡lise concluÃ­da!", state="complete")

    # Remove duplicatas das fontes coletadas, mantendo a ordem
    unique_sources = list({v['source_url']:v for v in all_sources_structured}.values())
    return final_answer, unique_sources

def main():
    st.markdown('<h1 style="color:#0b2859;">ğŸ¤– PRIA (Agente de IA para ILP)</h1>', unsafe_allow_html=True)
    st.markdown("---")

    # Criar placeholders para as mensagens de carregamento
    status_message_1 = st.empty()
    status_message_2 = st.empty()
    
    status_message_1.info("Carregando modelo de embedding...")
    # A linha abaixo deve ser executada apÃ³s o carregamento do modelo de embedding.
    # No seu cÃ³digo, a funÃ§Ã£o setup_and_load_data() faz isso.
    # Vou simular que o carregamento estÃ¡ acontecendo.
    
    # SimulaÃ§Ã£o do carregamento (vocÃª jÃ¡ tem a sua funÃ§Ã£o `setup_and_load_data`)
    # time.sleep(2)  
    
    status_message_1.success("âœ… Modelo de embedding carregado.")
    status_message_2.info("Carregando modelo de Re-ranking (Cross-Encoder)...")
    
    # A linha abaixo deve ser executada apÃ³s o carregamento do modelo de re-ranking.
    # time.sleep(2)
    
    # Suas chamadas de carregamento
    artifacts, summary_data, setores_disponiveis, controles_disponiveis, embedding_model, cross_encoder_model = setup_and_load_data()

    # Limpar os placeholders para que as mensagens nÃ£o fiquem na tela
    status_message_1.empty()
    status_message_2.empty()

    if not summary_data or not artifacts:
        st.error("âŒ Falha crÃ­tica no carregamento dos dados. O app nÃ£o pode continuar.")
        st.stop()

    artifacts, summary_data, setores_disponiveis, controles_disponiveis, embedding_model, cross_encoder_model = setup_and_load_data()
        
    if not summary_data or not artifacts:
        st.error("âŒ Falha crÃ­tica no carregamento dos dados. O app nÃ£o pode continuar.")
        st.stop()
    
    engine = AnalyticalEngine(summary_data, DICIONARIO_UNIFICADO_HIERARQUICO) 
    
    try:
        from catalog_data import company_catalog_rich 
    except ImportError:
        company_catalog_rich = [] 
    
    st.session_state.company_catalog_rich = company_catalog_rich

    
    from tools import _create_company_lookup_map
    st.session_state.company_lookup_map = _create_company_lookup_map(company_catalog_rich)


    with st.sidebar:
        st.header("ğŸ“Š InformaÃ§Ãµes do Sistema")
        st.metric("Categorias de Documentos (RAG)", "Item 8.4", "Plano de RemuneraÃ§Ã£o")
        
        st.markdown("---")
        st.header("ğŸ”’ Modo ApresentaÃ§Ã£o")
        anonimizar_empresas = st.checkbox(
            "Ocultar nomes de empresas",
            value=False,
            help="Substitui os nomes das empresas por placeholders como 'Empresa A', 'Empresa B' para garantir a confidencialidade durante a apresentaÃ§Ã£o."
        )
        
        st.markdown("---")

        
        prioritize_recency = st.checkbox(
            "Priorizar documentos mais recentes",
            value=True,
            help="DÃ¡ um bÃ´nus de relevÃ¢ncia para os documentos mais novos.")
        st.metric("Empresas no Resumo", len(summary_data))
        st.header("âš™ï¸ Filtros da AnÃ¡lise")
        st.caption("Filtre a base de dados antes de fazer sua pergunta.")
        
        selected_setor = st.selectbox(
            label="Filtrar por Setor",
            options=setores_disponiveis,
            index=0
        )
        
        selected_controle = st.selectbox(
            label="Filtrar por Controle AcionÃ¡rio",
            options=controles_disponiveis,
            index=0
        )
        st.markdown("---") 
        with st.expander("Empresas com dados no resumo"):
            st.dataframe(pd.DataFrame(sorted(list(summary_data.keys())), columns=["Empresa"]), use_container_width=True, hide_index=True)
        st.success("âœ… Sistema pronto para anÃ¡lise")
        st.info(f"Embedding Model: `{MODEL_NAME}`")
        st.info(f"Generative Model: `{GEMINI_MODEL}`")
    
    st.header("ğŸ’¬ FaÃ§a sua pergunta")
    
    with st.expander("â„¹ï¸ **Guia do UsuÃ¡rio: Como Extrair o MÃ¡ximo do Agente**", expanded=False):
        st.markdown("""
        Este agente foi projetado para atuar como um consultor especialista em Planos de Incentivo de Longo Prazo (ILP), analisando uma base de dados de documentos pÃºblicos da CVM. Para obter os melhores resultados, formule perguntas que explorem suas principais capacidades.
        """)
        st.subheader("1. Perguntas de Listagem (Quem tem?) ğŸ¯")
        st.info("Use estas perguntas para identificar e listar empresas que adotam uma prÃ¡tica especÃ­fica. Ideal para mapeamento de mercado.")
        st.code("""- Liste as empresas que pagam dividendos ou JCP durante o perÃ­odo de carÃªncia (vesting).
- Quais companhias possuem clÃ¡usulas de Malus ou Clawback?
- Gere uma lista de empresas que oferecem planos com contrapartida do empregador (Matching/Coinvestimento).
- Quais organizaÃ§Ãµes mencionam explicitamente o ComitÃª de RemuneraÃ§Ã£o como Ã³rgÃ£o aprovador dos planos?""")
        st.subheader("2. AnÃ¡lise EstatÃ­stica (Qual a mÃ©dia?) ğŸ“ˆ")
        st.info("Pergunte por mÃ©dias, medianas e outros dados estatÃ­sticos para entender os nÃºmeros por trÃ¡s das prÃ¡ticas de mercado e fazer benchmarks.")
        st.code("""- Qual o perÃ­odo mÃ©dio de vesting (em anos) entre as empresas analisadas?
- Qual a diluiÃ§Ã£o mÃ¡xima mÃ©dia (% do capital social) que os planos costumam aprovar?
- Apresente as estatÃ­sticas do desconto no preÃ§o de exercÃ­cio (mÃ­nimo, mÃ©dia, mÃ¡ximo).
- Qual o prazo de lock-up (restriÃ§Ã£o de venda) mais comum apÃ³s o vesting das aÃ§Ãµes?""")
        st.subheader("3. PadrÃµes de Mercado (Como Ã© o normal?) ğŸ—ºï¸")
        st.info("FaÃ§a perguntas abertas para que o agente analise diversos planos e descreva os padrÃµes e as abordagens mais comuns para um determinado tÃ³pico.")
        st.code("""- Analise os modelos tÃ­picos de planos de AÃ§Ãµes Restritas (RSU), o tipo mais comum no mercado.
- AlÃ©m do TSR, quais sÃ£o as metas de performance (ESG, Financeiras) mais utilizadas pelas empresas?
- Descreva os padrÃµes de tratamento para condiÃ§Ãµes de saÃ­da (Good Leaver vs. Bad Leaver) nos planos.
- Quais as abordagens mais comuns para o tratamento de dividendos em aÃ§Ãµes ainda nÃ£o investidas?""")
        st.subheader("4. AnÃ¡lise Profunda e Comparativa (Me explique em detalhes) ğŸ§ ")
        st.info("Use o poder do RAG para pedir anÃ¡lises detalhadas sobre uma ou mais empresas, comparando regras e estruturas especÃ­ficas.")
        st.code("""- Como o plano da Vale trata a aceleraÃ§Ã£o de vesting em caso de mudanÃ§a de controle?
- Compare as clÃ¡usulas de Malus/Clawback da Vale com as do ItaÃº.
- Descreva em detalhes o plano de OpÃ§Ãµes de Compra da Localiza, incluindo prazos, condiÃ§Ãµes e forma de liquidaÃ§Ã£o.
- Descreva o Item 8.4 da M.dias Braco.
- Quais as diferenÃ§as na elegibilidade de participantes entre os planos da Magazine Luiza e da Lojas Renner?""")
        st.subheader("â— Conhecendo as LimitaÃ§Ãµes")
        st.warning("""
- **Fonte dos Dados:** Minha anÃ¡lise se baseia em documentos pÃºblicos da CVM com data de corte 31/07/2025. NÃ£o tenho acesso a informaÃ§Ãµes em tempo real ou privadas.
- **IdentificaÃ§Ã£o de Nomes:** Para anÃ¡lises profundas, preciso que o nome da empresa seja claro e reconhecÃ­vel. Se o nome for ambÃ­guo ou nÃ£o estiver na minha base, posso nÃ£o encontrar os detalhes.
- **Escopo:** Sou altamente especializado em Incentivos de Longo Prazo. Perguntas fora deste domÃ­nio podem nÃ£o ter respostas adequadas.
        """)

    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Quais sÃ£o os modelos tÃ­picos de vesting? ou Como funciona o plano da Vale?")
    
    if st.button("ğŸ” Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("âš ï¸ Por favor, digite uma pergunta.")
            st.stop()
        active_filters = {}
        if selected_setor != "Todos":
            active_filters['setor'] = selected_setor.lower()
        if selected_controle != "Todos":
            active_filters['controle_acionario'] = selected_controle.lower()
        if active_filters:
            filter_text_parts = []
            if 'setor' in active_filters:
                filter_text_parts.append(f"**Setor**: {active_filters['setor'].capitalize()}")
            if 'controle_acionario' in active_filters:
                filter_text_parts.append(f"**Controle**: {active_filters['controle_acionario'].capitalize()}")

            filter_text = " e ".join(filter_text_parts)
            st.info(f"ğŸ” AnÃ¡lise sendo executada com os seguintes filtros: {filter_text}")

        st.markdown("---")
        st.subheader("ğŸ“‹ Resultado da AnÃ¡lise")
                
        intent = None
        query_lower = user_query.lower()
        
        quantitative_keywords = [
            'liste', 'quais empresas', 'quais companhias', 'quantas', 'mÃ©dia', 
            'mediana', 'estatÃ­sticas', 'mais comuns', 'prevalÃªncia', 'contagem'
        ]
        
        if any(keyword in query_lower for keyword in quantitative_keywords):
            intent = "quantitativa"
            logger.info("IntenÃ§Ã£o 'quantitativa' detectada por regras de palavras-chave.")
        
        if intent is None:
            with st.spinner("Analisando a intenÃ§Ã£o da sua pergunta..."):
                intent = get_query__with_llm(user_query)

        # [NOVA ADIÃ‡ÃƒO 1] Inicializa o mapa de anonimizaÃ§Ã£o que serÃ¡ usado em toda a anÃ¡lise.
        # Isso garante que a "Empresa A" seja sempre a mesma, seja no texto ou nas tabelas.
        mapa_anonimizacao = {}
                
        if intent == "quantitativa":
            st.info("IntenÃ§Ã£o quantitativa detectada. Usando o motor de anÃ¡lise rÃ¡pida...")
    
            with st.spinner("Executando anÃ¡lise quantitativa..."):
                report_text, data_result = engine.answer_query(user_query, filters=active_filters)
                
                # [NOVA ADIÃ‡ÃƒO 2] Verifica se o modo de anonimizaÃ§Ã£o estÃ¡ ativo.
                # Se estiver, passa o resultado pela funÃ§Ã£o anonimizar_resultados.
                if anonimizar_empresas and data_result is not None:
                    data_result, mapa_anonimizacao = anonimizar_resultados(data_result, st.session_state.company_catalog_rich)

                # A partir daqui, o cÃ³digo de exibiÃ§Ã£o renderizarÃ¡ a versÃ£o
                # original ou a anonimizada, dependendo do checkbox.
                if report_text:
                    st.markdown(report_text)
            
                if data_result is not None:
                    if isinstance(data_result, pd.DataFrame):
                        if not data_result.empty:
                            st.dataframe(data_result, use_container_width=True, hide_index=True)
                    elif isinstance(data_result, dict):
                        for df_name, df_content in data_result.items():
                            if isinstance(df_content, pd.DataFrame) and not df_content.empty:
                                st.markdown(f"#### {df_name}")
                                st.dataframe(df_content, use_container_width=True, hide_index=True)

        else: # intent == 'qualitativa'
            final_answer, sources = handle_rag_query(
                user_query, 
                artifacts, 
                embedding_model, 
                cross_encoder_model, 
                kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                company_catalog_rich=st.session_state.company_catalog_rich, 
                company_lookup_map=st.session_state.company_lookup_map, 
                summary_data=summary_data,
                filters=active_filters,
                prioritize_recency=prioritize_recency
            )
            
            # [NOVA ADIÃ‡ÃƒO 3] LÃ³gica de anonimizaÃ§Ã£o de duas etapas para o RAG.
            if anonimizar_empresas and sources:
                # 3.1: Cria o mapa de anonimizaÃ§Ã£o a partir da lista de fontes.
                df_sources = pd.DataFrame(sources)
                if not df_sources.empty:
                    df_sources.rename(columns={'company_name': 'Empresa'}, inplace=True)
                    df_sources_anon, mapa_anonimizacao = anonimizar_resultados(df_sources, st.session_state.company_catalog_rich)
                    sources = df_sources_anon.rename(columns={'Empresa': 'company_name'}).to_dict('records')

                # 3.2: Usa o mapa jÃ¡ criado para substituir os nomes no texto da resposta.
                final_answer, _ = anonimizar_resultados(final_answer, st.session_state.company_catalog_rich, mapa_anonimizacao)
            
            st.markdown(final_answer)
            
            if sources:
                with st.expander(f"ğŸ“š Documentos consultados ({len(sources)})", expanded=True):
                    st.caption("Nota: Links diretos para a CVM podem falhar. Use a busca no portal com o protocolo como plano B.")
    
                    for src in sorted(sources, key=lambda x: x.get('company_name', '')):
                        # Este cÃ³digo de exibiÃ§Ã£o agora usarÃ¡ os nomes anonimizados de 'sources'
                        company_name = src.get('company_name', 'N/A')
                        doc_date = src.get('document_date', 'N/A')
                        doc_type_raw = src.get('doc_type', '')
                        url = src.get('source_url', '')

                        if doc_type_raw == 'outros_documentos':
                            display_doc_type = 'Plano de RemuneraÃ§Ã£o'
                        else:
                            display_doc_type = doc_type_raw.replace('_', ' ')
    
                        display_text = f"{company_name} - {display_doc_type} - (Data: **{doc_date}**)"
                        
                        if "frmExibirArquivoIPEExterno" in url:
                            protocolo_match = re.search(r'NumeroProtocoloEntrega=(\d+)', url)
                            protocolo = protocolo_match.group(1) if protocolo_match else "N/A"
                            st.markdown(f"**{display_text}** (Protocolo: **{protocolo}**)")
                            st.markdown(f"â†³ [Link Direto para Plano de ILP]({url}) ", unsafe_allow_html=True)
            
                        elif "frmExibirArquivoFRE" in url:
                            st.markdown(f"**{display_text}**")
                            st.markdown(f"â†³ [Link Direto para FormulÃ¡rio de ReferÃªncia]({url})", unsafe_allow_html=True)
            
                        else:
                            st.markdown(f"**{display_text}**: [Link]({url})")


if __name__ == "__main__":
    main()
