# app.py (vers√£o com Melhoria 1 e 2)

import streamlit as st
import json
import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, CrossEncoder
import requests
import re
import unicodedata
import logging
from pathlib import Path
import zipfile
import io
import shutil
import random
from concurrent.futures import ThreadPoolExecutor # <<< MELHORIA 4 ADICIONADA
from tools import (
    find_companies_by_topic,
    get_final_unified_answer,
    suggest_alternative_query,
    analyze_topic_thematically, 
    get_summary_for_topic_at_company,
    rerank_with_cross_encoder,
    create_hierarchical_alias_map
    )
logger = logging.getLogger(__name__)

# --- M√≥dulos do Projeto (devem estar na mesma pasta) ---
from knowledge_base import DICIONARIO_UNIFICADO_HIERARQUICO
from analytical_engine import AnalyticalEngine

# --- Configura√ß√µes Gerais ---
st.set_page_config(page_title="Agente de An√°lise LTIP", page_icon="üîç", layout="wide", initial_sidebar_state="expanded")

MODEL_NAME = 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2'
TOP_K_SEARCH = 7
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "")
GEMINI_MODEL = "gemini-2.0-flash-lite"
CVM_SEARCH_URL = "https://www.rad.cvm.gov.br/ENET/frmConsultaExternaCVM.aspx"

FILES_TO_DOWNLOAD = {
    "item_8_4_chunks_map_final.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/item_8_4_chunks_map_final.json",
    "item_8_4_faiss_index_final.bin": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/item_8_4_faiss_index_final.bin",
    "outros_documentos_chunks_map_final.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/outros_documentos_chunks_map_final.json",
    "outros_documentos_faiss_index_final.bin": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/outros_documentos_faiss_index_final.bin",
    "resumo_fatos_e_topicos_final_enriquecido.json": "https://github.com/tovarich86/agentev3/releases/download/V2.0-DATA/resumo_fatos_e_topicos_final_enriquecido.json"
}
CACHE_DIR = Path("data_cache")
SUMMARY_FILENAME = "resumo_fatos_e_topicos_final_enriquecido.json"

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- CARREGADOR DE DADOS ---
@st.cache_resource(show_spinner="Configurando o ambiente e baixando dados...")
def setup_and_load_data():
    CACHE_DIR.mkdir(exist_ok=True)
    
    for filename, url in FILES_TO_DOWNLOAD.items():
        local_path = CACHE_DIR / filename
        if not local_path.exists():
            logger.info(f"Baixando arquivo '{filename}'...")
            try:
                response = requests.get(url, stream=True, timeout=60)
                response.raise_for_status()
                with open(local_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                logger.info(f"'{filename}' baixado com sucesso.")
            except requests.exceptions.RequestException as e:
                st.error(f"Erro ao baixar {filename} de {url}: {e}")
                st.stop()
    # --- Carregamento de Modelos ---
    st.write("Carregando modelo de embedding...")
    embedding_model = SentenceTransformer(MODEL_NAME)
    
    st.write("Carregando modelo de Re-ranking (Cross-Encoder)...")
    cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
    
    artifacts = {}
    for index_file in CACHE_DIR.glob('*_faiss_index_final.bin'):
        category = index_file.stem.replace('_faiss_index_final', '')
        chunks_file = CACHE_DIR / f"{category}_chunks_map_final.json"
        try:
            artifacts[category] = {
                'index': faiss.read_index(str(index_file)),
                'chunks': json.load(open(chunks_file, 'r', encoding='utf-8'))
            }
        except Exception as e:
            st.error(f"Falha ao carregar artefatos para a categoria '{category}': {e}")
            st.stop()

    summary_file_path = CACHE_DIR / SUMMARY_FILENAME
    try:
        with open(summary_file_path, 'r', encoding='utf-8') as f:
            summary_data = json.load(f)
    except FileNotFoundError:
        st.error(f"Erro cr√≠tico: '{SUMMARY_FILENAME}' n√£o foi encontrado.")
        st.stop()

    setores = set()
    controles = set()

    for artifact_data in artifacts.values():
        chunk_map = artifact_data.get('chunks', {}).get('map', [])
        for metadata in chunk_map:
            # Pega o valor do setor e trata se for nulo ou vazio
            setor = metadata.get('setor')
            if isinstance(setor, str) and setor.strip():
                setores.add(setor.strip().capitalize())
            else:
                setores.add("N√£o idenficado") # <-- L√ìGICA ADICIONADA

            # Pega o valor do controle e trata se for nulo ou vazio
            controle = metadata.get('controle_acionario')
            if isinstance(controle, str) and controle.strip():
                controles.add(controle.strip().capitalize())
            else:
                controles.add("N√£o identificado") # <-- L√ìGICA ADICIONADA

    # Converte os sets em listas ordenadas e adiciona "Todos" no in√≠cio
    # Garante que "N√£o Informado" n√£o seja o primeiro da lista, se existir.
    sorted_setores = sorted([s for s in setores if s != "N√£o Informado"])
    if "N√£o Informado" in setores:
        sorted_setores.append("N√£o Informado")

    sorted_controles = sorted([c for c in controles if c != "N√£o Informado"])
    if "N√£o Informado" in controles:
        sorted_controles.append("N√£o Informado")

    all_setores = ["Todos"] + sorted_setores
    all_controles = ["Todos"] + sorted_controles

    logger.info(f"Filtros din√¢micos encontrados: {len(all_setores)-1} setores e {len(all_controles)-1} tipos de controle.")

    # --- FIM DA L√ìGICA DE EXTRA√á√ÉO REFINADA ---
        
    return embedding_model, cross_encoder_model, artifacts, summary_data, all_setores, all_controles




# --- FUN√á√ïES GLOBAIS E DE RAG ---

def _create_flat_alias_map(kb: dict) -> dict:
    alias_to_canonical = {}
    for section, topics in kb.items():
        for topic_name_raw, aliases in topics.items():
            canonical_name = topic_name_raw.replace('_', ' ')
            alias_to_canonical[canonical_name.lower()] = canonical_name
            for alias in aliases:
                alias_to_canonical[alias.lower()] = canonical_name
    return alias_to_canonical

AVAILABLE_TOPICS = list(set(_create_flat_alias_map(DICIONARIO_UNIFICADO_HIERARQUICO).values()))

def expand_search_terms(base_term: str, kb: dict) -> list[str]:
    base_term_lower = base_term.lower()
    expanded_terms = {base_term_lower}
    for section, topics in kb.items():
        for topic, aliases in topics.items():
            all_terms_in_group = {alias.lower() for alias in aliases} | {topic.lower().replace('_', ' ')}
            if base_term_lower in all_terms_in_group:
                expanded_terms.update(all_terms_in_group)
    return list(expanded_terms)

# Em app.py, substitua esta fun√ß√£o
def search_by_tags(chunks_to_search: list[dict], target_tags: list[str]) -> list[dict]:
    """Busca chunks que contenham tags de t√≥picos espec√≠ficos."""
    results = []
    target_tags_lower = {tag.lower() for tag in target_tags}

    for i, chunk_info in enumerate(chunks_to_search):
        chunk_text = chunk_info.get("text", "")
        found_topics_in_chunk = re.findall(r'\[topico:([^\]]+)\]', chunk_text)

        if found_topics_in_chunk:
            # O t√≥pico pode ser uma lista, ex: [topico:Vesting,Aceleracao]
            topics_in_chunk_set = {t.strip().lower() for t in found_topics_in_chunk[0].split(',')}

            # Se houver qualquer sobreposi√ß√£o entre as tags procuradas e as encontradas
            if not target_tags_lower.isdisjoint(topics_in_chunk_set):
                results.append(chunk_info)
    return results

def get_final_unified_answer(query: str, context: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    has_complete_8_4 = "formul√°rio de refer√™ncia" in query.lower() and "8.4" in query.lower()
    has_tagged_chunks = "--- CONTE√öDO RELEVANTE" in context
    structure_instruction = "Organize a resposta de forma l√≥gica e clara usando Markdown."
    if has_complete_8_4:
        structure_instruction = "ESTRUTURA OBRIGAT√ìRIA PARA ITEM 8.4: Use a estrutura oficial do item 8.4 do Formul√°rio de Refer√™ncia (a, b, c...)."
    elif has_tagged_chunks:
        structure_instruction = "PRIORIZE as informa√ß√µes dos chunks recuperados e organize a resposta de forma l√≥gica."
    prompt = f"""Voc√™ √© um consultor especialista em planos de incentivo de longo prazo (ILP).
    PERGUNTA ORIGINAL DO USU√ÅRIO: "{query}"
    CONTEXTO COLETADO DOS DOCUMENTOS:
    {context}
    {structure_instruction}
    INSTRU√á√ïES PARA O RELAT√ìRIO FINAL:
    1. Responda diretamente √† pergunta do usu√°rio com base no contexto fornecido.
    2. Seja detalhado, preciso e profissional na sua linguagem. Use formata√ß√£o Markdown.
    3. Se uma informa√ß√£o espec√≠fica pedida n√£o estiver no contexto, declare explicitamente: "Informa√ß√£o n√£o encontrada nas fontes analisadas.". N√£o invente dados.
    RELAT√ìRIO ANAL√çTICO FINAL:"""
    payload = {"contents": [{"parts": [{"text": prompt}]}]}
    headers = {'Content-Type': 'application/json'}
    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=180)
        response.raise_for_status()
        return response.json()['candidates'][0]['content']['parts'][0]['text'].strip()
    except Exception as e:
        logger.error(f"ERRO ao gerar resposta final com LLM: {e}")
        return f"Ocorreu um erro ao contatar o modelo de linguagem. Detalhes: {str(e)}"

# <<< MELHORIA 1 ADICIONADA >>>
def get_query_intent_with_llm(query: str) -> str:
    """
    Usa um LLM para classificar a inten√ß√£o do usu√°rio em 'quantitativa' ou 'qualitativa'.
    Retorna 'qualitativa' como padr√£o em caso de erro.
    """
    url = f"https://generativelanguage.googleapis.com/v1beta/models/{GEMINI_MODEL}:generateContent?key={GEMINI_API_KEY}"
    
    prompt = f"""
    Analise a pergunta do usu√°rio e classifique a sua inten√ß√£o principal. Responda APENAS com uma √∫nica palavra em JSON.
    
    As op√ß√µes de classifica√ß√£o s√£o:
    1. "quantitativa": Se a pergunta busca por n√∫meros, listas diretas, contagens, m√©dias, estat√≠sticas ou agrega√ß√µes. 
       Exemplos: "Quantas empresas t√™m TSR Relativo?", "Qual a m√©dia de vesting?", "Liste as empresas com desconto no strike.".
    2. "qualitativa": Se a pergunta busca por explica√ß√µes, detalhes, compara√ß√µes, descri√ß√µes ou an√°lises aprofundadas.
       Exemplos: "Como funciona o plano da Vale?", "Compare os planos da Hypera e Movida.", "Detalhe o tratamento de dividendos.".

    Pergunta do Usu√°rio: "{query}"

    Responda apenas com o JSON da classifica√ß√£o. Exemplo de resposta: {{"intent": "qualitativa"}}
    """
    
    payload = {
        "contents": [{"parts": [{"text": prompt}]}],
        "generationConfig": {
            "temperature": 0.0,
            "maxOutputTokens": 50
        }
    }
    headers = {'Content-Type': 'application/json'}

    try:
        response = requests.post(url, headers=headers, data=json.dumps(payload), timeout=30)
        response.raise_for_status()
        
        response_text = response.json()['candidates'][0]['content']['parts'][0]['text']
        intent_json = json.loads(re.search(r'\{.*\}', response_text, re.DOTALL).group())
        intent = intent_json.get("intent", "qualitativa").lower()
        
        logger.info(f"Inten√ß√£o detectada pelo LLM: '{intent}' para a pergunta: '{query}'")
        
        if intent in ["quantitativa", "qualitativa"]:
            return intent
        else:
            logger.warning(f"Inten√ß√£o n√£o reconhecida '{intent}'. Usando 'qualitativa' como padr√£o.")
            return "qualitativa"

    except Exception as e:
        logger.error(f"ERRO ao determinar inten√ß√£o com LLM: {e}. Usando 'qualitativa' como padr√£o.")
        return "qualitativa"

# <<< MELHORIA 2 APLICADA >>>
# Fun√ß√£o modificada para lidar com buscas gerais (sem empresa)
# Em app.py, substitua esta fun√ß√£o
def execute_dynamic_plan(
    query: str,
    plan: dict,
    artifacts: dict,
    model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,
    # Fun√ß√µes auxiliares como depend√™ncias expl√≠citas
    search_by_tags: callable,
    expand_search_terms: callable
) -> tuple[str, list[dict]]:
    """
    Vers√£o 4.0 (Definitiva e Completa) do Executor de Planos.

    Esta fun√ß√£o implementa uma pipeline de 3 est√°gios sem omiss√µes ou simplifica√ß√µes:
    1. PR√â-FILTRA chunks por metadados (setor, controle) para efici√™ncia.
    2. ROTEIA a execu√ß√£o com base no tipo de plano, usando a l√≥gica completa da vers√£o original.
    3. EXECUTA buscas h√≠bridas (tags + vetorial) no conjunto de dados pr√©-filtrado.
    4. RE-RANQUEIA os resultados finais para m√°xima precis√£o.
    """
    logger.info(f"Executando plano v4.0 (Definitivo) para query: '{query}'")

    # --- EST√ÅGIO 0: CONFIGURA√á√ÉO E FUN√á√ïES AUXILIARES ---
    candidate_chunks_dict = {}
    TOP_K_INITIAL_RETRIEVAL = 30
    TOP_K_FINAL = 10

    plan_type = plan.get("plan_type", "default")
    empresas = plan.get("empresas", [])
    topicos = plan.get("topicos", [])
    filtros = plan.get("filtros", {})

    def _is_company_match(plan_canonical_name: str, metadata_name: str) -> bool:
        if not plan_canonical_name or not metadata_name: return False
        chunk_canonical_name = company_lookup_map.get(metadata_name.lower())
        if chunk_canonical_name and chunk_canonical_name.lower() == plan_canonical_name.lower():
            return True
        searchable_part = unicodedata.normalize('NFKD', plan_canonical_name.lower()).encode('ascii', 'ignore').decode('utf-8').split(' ')[0]
        return searchable_part in metadata_name.lower()

    def add_candidate(chunk_info: dict):
        chunk_hash = hash(chunk_info.get("text", ""))
        if chunk_hash not in candidate_chunks_dict:
            candidate_chunks_dict[chunk_hash] = chunk_info

    # --- EST√ÅGIO 1: PR√â-FILTRAGEM GLOBAL ---
    pre_filtered_chunks = []
    for artifact_name, artifact_data in artifacts.items():
        chunk_map = artifact_data.get('chunks', {}).get('map', [])
        all_text_chunks = artifact_data.get('chunks', {}).get('chunks', [])
        if not chunk_map or not all_text_chunks or len(chunk_map) != len(all_text_chunks): continue
        for i, chunk_meta in enumerate(chunk_map):
            # Enriquece o metadado com o texto e o tipo de documento
            chunk_meta['text'] = all_text_chunks[i]
            chunk_meta['doc_type'] = artifact_name
            pre_filtered_chunks.append(chunk_meta)
    
    if filtros.get('setor'):
        pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('setor', '').lower() == filtros['setor'].lower()]
    if filtros.get('controle_acionario'):
        pre_filtered_chunks = [c for c in pre_filtered_chunks if c.get('controle_acionario', '').lower() == filtros['controle_acionario'].lower()]

    logger.info(f"Ap√≥s pr√©-filtragem por metadados, {len(pre_filtered_chunks)} chunks s√£o candidatos iniciais.")

    # --- EST√ÅGIO 2: ROTEAMENTO E BUSCA H√çBRIDA DETALHADA ---
    
    # ROTA 1: Plano especial para buscar o Item 8.4
    if plan_type == "section_8_4" and empresas:
        canonical_name_from_plan = empresas[0]
        search_name = next((e.get("search_alias", canonical_name_from_plan) for e in company_catalog_rich if e.get("canonical_name") == canonical_name_from_plan), canonical_name_from_plan)
        logger.info(f"ROTA section_8_4: Usando nome de busca '{search_name}' para '{canonical_name_from_plan}'")
        
        # Filtra ainda mais os chunks para o documento e empresa espec√≠ficos
        chunks_to_search = [c for c in pre_filtered_chunks if c.get('doc_type') == 'item_8_4' and _is_company_match(canonical_name_from_plan, c.get('company_name', ''))]
        if chunks_to_search:
            # Constr√≥i um √≠ndice FAISS tempor√°rio para esta busca espec√≠fica e otimizada
            temp_embeddings = model.encode([c['text'] for c in chunks_to_search], normalize_embeddings=True).astype('float32')
            temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
            temp_index.add(temp_embeddings)
            
            search_query = f"detalhes sobre os t√≥picos {', '.join(topicos)} do item 8.4 da empresa {search_name}"
            query_embedding = model.encode([search_query], normalize_embeddings=True).astype('float32')
            
            _, indices = temp_index.search(query_embedding, min(TOP_K_INITIAL_RETRIEVAL, len(chunks_to_search)))
            for idx in indices[0]:
                if idx != -1: add_candidate(chunks_to_search[idx])

    # ROTA 2: Planos Padr√£o (Default, Summary)
    else:
        # CASO 2.1: Busca geral por t√≥pico (sem empresa)
        if not empresas and topicos:
            logger.info(f"ROTA Default (Geral): Executando busca conceitual para os t√≥picos: {topicos}")
                    # --- OTIMIZA√á√ÉO AQUI ---
            sample_size = 2000 # Pega uma amostra de 4000 chunks para a busca geral
            if len(pre_filtered_chunks) > sample_size:
                logger.info(f"Base de chunks grande ({len(pre_filtered_chunks)}). Usando uma amostra de {sample_size} para a busca geral.")
                chunks_to_search = random.sample(pre_filtered_chunks, sample_size)
            else:
                chunks_to_search = pre_filtered_chunks
        # --- FIM DA OTIMIZA√á√ÉO ---
            # Constr√≥i √≠ndice FAISS tempor√°rio com todos os chunks pr√©-filtrados
            temp_embeddings = model.encode([c['text'] for c in chunks_to_search], normalize_embeddings=True).astype('float32')
            temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
            temp_index.add(temp_embeddings)
            
            for topico in topicos:
                for term in expand_search_terms(topico, kb)[:3]:
                    search_query = f"explica√ß√£o detalhada sobre o conceito e funcionamento de {term}"
                    query_embedding = model.encode([search_query], normalize_embeddings=True).astype('float32')
                    _, indices = temp_index.search(query_embedding, TOP_K_FINAL)
                    for idx in indices[0]:
                        if idx != -1: add_candidate(pre_filtered_chunks[idx])

        # CASO 2.2: Busca por empresa e t√≥picos (incluindo resumos) - A MAIS COMPLETA
        elif empresas and topicos:
            logger.info(f"ROTA Default (H√≠brida): Executando busca para Empresas: {empresas} e T√≥picos: {topicos}")
            for empresa_canonica in empresas:
                # Filtra os chunks para a empresa atual
                chunks_for_company = [c for c in pre_filtered_chunks if _is_company_match(empresa_canonica, c.get('company_name', ''))]
                if not chunks_for_company: continue

                # Parte 1: Busca por Tags (Alta Precis√£o)
                target_tags = set().union(*(expand_search_terms(t, kb) for t in topicos))
                # A fun√ß√£o search_by_tags √© adaptada para buscar na lista de chunks em mem√≥ria
                tagged_chunks = search_by_tags(chunks_for_company, list(target_tags))
                for chunk_info in tagged_chunks:
                    add_candidate(chunk_info)
                
                # Parte 2: Busca Vetorial (Alta Revoca√ß√£o Sem√¢ntica)
                temp_embeddings = model.encode([c['text'] for c in chunks_for_company], normalize_embeddings=True).astype('float32')
                temp_index = faiss.IndexFlatIP(temp_embeddings.shape[1])
                temp_index.add(temp_embeddings)
                
                search_name = next((e.get("search_alias", empresa_canonica) for e in company_catalog_rich if e.get("canonical_name") == empresa_canonica), empresa_canonica)
                
                for topico in topicos:
                    search_query = f"informa√ß√µes detalhadas sobre {topico} no plano da empresa {search_name}"
                    query_embedding = model.encode([search_query], normalize_embeddings=True).astype('float32')
                    _, indices = temp_index.search(query_embedding, min(TOP_K_INITIAL_RETRIEVAL, len(chunks_for_company)))
                    for idx in indices[0]:
                        if idx != -1: add_candidate(chunks_for_company[idx])

    # --- EST√ÅGIO 3: RE-RANKING FINAL ---
    if not candidate_chunks_dict:
        logger.warning(f"Nenhum chunk candidato encontrado para a query: '{query}' com os filtros aplicados.")
        return "N√£o encontrei informa√ß√µes relevantes para esta combina√ß√£o espec√≠fica de consulta e filtros.", []
    
    candidate_list = list(candidate_chunks_dict.values())
    logger.info(f"Total de {len(candidate_list)} chunks candidatos √∫nicos encontrados. Re-ranqueando...")
    
    reranked_chunks = rerank_with_cross_encoder(query, candidate_list, cross_encoder_model, top_n=TOP_K_FINAL)
    
    # Constru√ß√£o do Contexto Final
    full_context = ""
    retrieved_sources = []
    seen_sources = set()

    for chunk in reranked_chunks:
        company_name = chunk.get('company_name', 'N/A')
        source_url = chunk.get('source_url', 'N/A')
        
        source_header = f"(Empresa: {company_name}, Setor: {chunk.get('setor', 'N/A')}, Documento: {chunk.get('doc_type', 'N/A')})"
        clean_text = re.sub(r'\[.*?\]', '', chunk.get('text', '')).strip()
        full_context += f"--- CONTE√öDO RELEVANTE {source_header} ---\n{clean_text}\n\n"
        
        source_tuple = (company_name, source_url)
        if source_tuple not in seen_sources:
            seen_sources.add(source_tuple)
            retrieved_sources.append(chunk)
            
    logger.info(f"Contexto final constru√≠do a partir de {len(reranked_chunks)} chunks re-ranqueados.")
    return full_context, retrieved_sources
    
def create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters: dict):
    """
    Vers√£o 3.0 (Unificada) do planejador din√¢mico.

    Esta vers√£o combina o melhor de ambas as propostas:
    1.  EXTRAI filtros de metadados (setor, controle acion√°rio).
    2.  EXTRAI t√≥picos hier√°rquicos completos.
    3.  RESTAURA a detec√ß√£o de inten√ß√£o de "Resumo Geral" para perguntas abertas.
    4.  MANT√âM a detec√ß√£o da inten√ß√£o especial "Item 8.4".
    """
    logger.info(f"Gerando plano din√¢mico v3.0 para a pergunta: '{query}'")
    query_lower = query.lower().strip()
    
    plan = {
        "empresas": [],
        "topicos": [],
        "filtros": filters.copy(),
        "plan_type": "default" # O tipo de plano default aciona a busca RAG padr√£o.
    }



    # --- PASSO 2: Identifica√ß√£o Robusta de Empresas (L√≥gica Original Mantida) ---
    mentioned_companies = []
    if company_catalog_rich:
        companies_found_by_alias = {}
        for company_data in company_catalog_rich:
            canonical_name = company_data.get("canonical_name")
            if not canonical_name: continue
            
            all_aliases = company_data.get("aliases", []) + [canonical_name]
            for alias in all_aliases:
                if re.search(r'\b' + re.escape(alias.lower()) + r'\b', query_lower):
                    score = len(alias.split())
                    if canonical_name not in companies_found_by_alias or score > companies_found_by_alias[canonical_name]:
                        companies_found_by_alias[canonical_name] = score
        if companies_found_by_alias:
            mentioned_companies = [c for c, s in sorted(companies_found_by_alias.items(), key=lambda item: item[1], reverse=True)]

    if not mentioned_companies:
        for empresa_nome in summary_data.keys():
            if re.search(r'\b' + re.escape(empresa_nome.lower()) + r'\b', query_lower):
                mentioned_companies.append(empresa_nome)
    
    plan["empresas"] = mentioned_companies
    logger.info(f"Empresas identificadas: {plan['empresas']}")

    # --- PASSO 3: Detec√ß√£o de Inten√ß√µes Especiais (L√ìGICA UNIFICADA) ---
    # Palavras-chave para as inten√ß√µes especiais
    summary_keywords = ['resumo geral', 'plano completo', 'como funciona o plano', 'descreva o plano', 'resumo do plano', 'detalhes do plano']
    section_8_4_keywords = ['item 8.4', 'se√ß√£o 8.4', '8.4 do fre']
    
    is_summary_request = any(keyword in query_lower for keyword in summary_keywords)
    is_section_8_4_request = any(keyword in query_lower for keyword in section_8_4_keywords)

    if plan["empresas"] and is_section_8_4_request:
        plan["plan_type"] = "section_8_4"
        # O t√≥pico √© o caminho hier√°rquico para a se√ß√£o inteira
        plan["topicos"] = ["FormularioReferencia,Item_8_4"]
        logger.info("Plano especial 'section_8_4' detectado.")
        return {"status": "success", "plan": plan}
    
    # [L√ìGICA RESTAURADA E ADAPTADA]
    # Se for uma pergunta de resumo para uma empresa, define um conjunto de t√≥picos essenciais.
    elif plan["empresas"] and is_summary_request:
        plan["plan_type"] = "summary" # Um tipo especial para indicar um resumo completo
        logger.info("Plano especial 'summary' detectado. Montando plano com t√≥picos essenciais.")
        # Define os CAMINHOS HIER√ÅRQUICOS essenciais para um bom resumo.
        plan["topicos"] = [
            "TiposDePlano",
            "ParticipantesCondicoes,Elegibilidade",
            "Mecanicas,Vesting",
            "Mecanicas,Lockup",
            "IndicadoresPerformance",
            "GovernancaRisco,MalusClawback",
            "EventosFinanceiros,DividendosProventos"
        ]
        return {"status": "success", "plan": plan}

    # --- PASSO 4: Extra√ß√£o de T√≥picos Hier√°rquicos (Se Nenhuma Inten√ß√£o Especial Foi Ativada) ---
    alias_map = create_hierarchical_alias_map(kb)
    found_topics = set()
    
    # Ordena os aliases por comprimento para encontrar o mais espec√≠fico primeiro
    for alias in sorted(alias_map.keys(), key=len, reverse=True):
        # Usamos uma regex mais estrita para evitar matches parciais (ex: 'TSR' em 'TSR Relativo')
        if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
            found_topics.add(alias_map[alias])
    
    plan["topicos"] = sorted(list(found_topics))
    if plan["topicos"]:
        logger.info(f"Caminhos de t√≥picos identificados: {plan['topicos']}")

    # --- PASSO 5: Valida√ß√£o Final ---
    if not plan["empresas"] and not plan["topicos"] and not plan["filtros"]:
        logger.warning("Planejador n√£o conseguiu identificar empresa, t√≥pico ou filtro na pergunta.")
        return {"status": "error", "message": "N√£o foi poss√≠vel identificar uma inten√ß√£o clara na sua pergunta. Tente ser mais espec√≠fico."}
        
    return {"status": "success", "plan": plan}

    
def analyze_single_company(
    empresa: str, 
    plan: dict, 
    query: str,  # Novo argumento
    artifacts: dict, 
    model: SentenceTransformer, 
    cross_encoder_model: CrossEncoder, # Novo argumento
    kb: dict,
    execute_dynamic_plan_func: callable,
    get_final_unified_answer_func: callable
) -> dict:
    """
    Executa o plano de an√°lise para uma √∫nica empresa e retorna um dicion√°rio estruturado.
    Esta fun√ß√£o √© projetada para ser executada em um processo paralelo.
    """
    single_plan = {'empresas': [empresa], 'topicos': plan['topicos']}
    
    # --- CORRE√á√ÉO APLICADA AQUI ---
    # Adicionado o argumento 'is_summary_plan=False' na chamada.
    context, sources_list = execute_dynamic_plan_func(query, single_plan, artifacts, model, cross_encoder_model, kb)
    
    result_data = {
        "empresa": empresa,
        "resumos_por_topico": {topico: "Informa√ß√£o n√£o encontrada" for topico in plan['topicos']},
        "sources": sources_list
    }

    if context:
        summary_prompt = f"""
        Com base no CONTEXTO abaixo sobre a empresa {empresa}, crie um resumo para cada um dos T√ìPICOS solicitados.
        Sua resposta deve ser APENAS um objeto JSON v√°lido, sem nenhum texto adicional antes ou depois.
        
        T√ìPICOS PARA RESUMIR: {json.dumps(plan['topicos'])}
        
        CONTEXTO:
        {context}
        
        FORMATO OBRIGAT√ìRIO DA RESPOSTA (APENAS JSON):
        {{
          "resumos_por_topico": {{
            "T√≥pico 1": "Resumo conciso sobre o T√≥pico 1...",
            "T√≥pico 2": "Resumo conciso sobre o T√≥pico 2...",
            "...": "..."
          }}
        }}
        """
        
        try:
            json_response_str = get_final_unified_answer_func(summary_prompt, context)
            json_match = re.search(r'\{.*\}', json_response_str, re.DOTALL)
            if json_match:
                parsed_json = json.loads(json_match.group())
                result_data["resumos_por_topico"] = parsed_json.get("resumos_por_topico", result_data["resumos_por_topico"])
            else:
                logger.warning(f"N√£o foi poss√≠vel extrair JSON da resposta para a empresa {empresa}.")

        except (json.JSONDecodeError, Exception) as e:
            logger.error(f"Erro ao processar o resumo JSON para {empresa}: {e}")
            
    return result_data


def handle_rag_query(
    query: str,
    artifacts: dict,
    embedding_model: SentenceTransformer,
    cross_encoder_model: CrossEncoder,
    kb: dict,
    company_catalog_rich: list,
    company_lookup_map: dict,  # <-- ESTE √â O PAR√ÇMETRO QUE FALTAVA
    summary_data: dict,
    filters: dict
) -> tuple[str, list[dict]]:
    """
    Orquestra o pipeline de RAG para perguntas qualitativas, incluindo a gera√ß√£o do plano,
    a execu√ß√£o da busca (com re-ranking) e a s√≠ntese da resposta final.
    """
    with st.status("1Ô∏è‚É£ Gerando plano de an√°lise...", expanded=True) as status:
        plan_response = create_dynamic_analysis_plan(query, company_catalog_rich, kb, summary_data, filters)
        
        if plan_response['status'] != "success":
            status.update(label="‚ö†Ô∏è Falha na identifica√ß√£o", state="error", expanded=True)
            
            st.warning("N√£o consegui identificar uma empresa conhecida na sua pergunta para realizar uma an√°lise profunda.")
            st.info("Para an√°lises detalhadas, por favor, use o nome de uma das empresas listadas na barra lateral.")
            
            with st.spinner("Estou pensando em uma pergunta alternativa que eu possa responder..."):
                alternative_query = suggest_alternative_query(query)
            
            st.markdown("#### Que tal tentar uma pergunta mais geral?")
            st.markdown("Voc√™ pode copiar a sugest√£o abaixo ou reformular sua pergunta original.")
            st.code(alternative_query, language=None)
            
            # Retornamos uma string vazia para o texto e para as fontes, encerrando a an√°lise de forma limpa.
            return "", []
        # --- FIM DO NOVO BLOCO ---
            
        plan = plan_response['plan']
        
        summary_keywords = ['resumo', 'geral', 'completo', 'vis√£o geral', 'como funciona o plano', 'detalhes do plano']
        is_summary_request = any(keyword in query.lower() for keyword in summary_keywords)
        
        specific_topics_in_query = list({canonical for alias, canonical in _create_flat_alias_map(kb).items() if re.search(r'\b' + re.escape(alias) + r'\b', query.lower())})
        is_summary_plan = is_summary_request and not specific_topics_in_query
        
        if plan['empresas']:
            st.write(f"**üè¢ Empresas identificadas:** {', '.join(plan['empresas'])}")
        else:
            st.write("**üè¢ Nenhuma empresa espec√≠fica identificada. Realizando busca geral.**")
            
        st.write(f"**üìù T√≥picos a analisar:** {', '.join(plan['topicos'])}")
        if is_summary_plan:
            st.info("üí° Modo de resumo geral ativado. A busca ser√° otimizada para os t√≥picos encontrados.")
            
        status.update(label="‚úÖ Plano gerado com sucesso!", state="complete")

    final_answer, all_sources_structured = "", []
    seen_sources_tuples = set()

    # --- L√≥gica para M√∫ltiplas Empresas (Compara√ß√£o) ---
    if len(plan.get('empresas', [])) > 1:
        st.info(f"Modo de compara√ß√£o ativado para {len(plan['empresas'])} empresas. Executando an√°lises em paralelo...")
        
        with st.spinner(f"Analisando {len(plan['empresas'])} empresas..."):
            with ThreadPoolExecutor(max_workers=len(plan['empresas'])) as executor:
                futures = [
                    executor.submit(
                        analyze_single_company, 
                        empresa, plan, query, artifacts, embedding_model, cross_encoder_model, kb,
                        execute_dynamic_plan, get_final_unified_answer
                    ) 
                    for empresa in plan['empresas']
                ]
                results = [future.result() for future in futures]

        for result in results:
            for src_dict in result.get('sources', []):
                company_name = src_dict.get('company_name')
                source_url = src_dict.get('source_url')
                
                if company_name and source_url:
                    src_tuple = (company_name, source_url)
                    if src_tuple not in seen_sources_tuples:
                        seen_sources_tuples.add(src_tuple)
                        all_sources_structured.append(src_dict)

        with st.status("Gerando relat√≥rio comparativo final...", expanded=True) as status:
            structured_context = json.dumps(results, indent=2, ensure_ascii=False)
            comparison_prompt = f"""
            Sua tarefa √© criar um relat√≥rio comparativo detalhado sobre "{query}".
            Use os dados estruturados fornecidos no CONTEXTO JSON abaixo.
            O relat√≥rio deve come√ßar com uma breve an√°lise textual e, em seguida, apresentar uma TABELA MARKDOWN clara e bem formatada.

            CONTEXTO (em formato JSON):
            {structured_context}
            """
            final_answer = get_final_unified_answer(comparison_prompt, structured_context)
            status.update(label="‚úÖ Relat√≥rio comparativo gerado!", state="complete")
            
    # --- L√≥gica para Empresa √önica ou Busca Geral ---
    else:
        with st.status("2Ô∏è‚É£ Recuperando e re-ranqueando contexto...", expanded=True) as status:
            context, all_sources_structured = execute_dynamic_plan(
                query, plan, artifacts, embedding_model, cross_encoder_model, kb,company_catalog_rich, company_lookup_map, search_by_tags, expand_search_terms)
            
            if not context:
                st.error("‚ùå N√£o encontrei informa√ß√µes relevantes nos documentos para a sua consulta.")
                return "Nenhuma informa√ß√£o relevante encontrada.", []
                
            st.write(f"**üìÑ Contexto recuperado de:** {len(all_sources_structured)} documento(s)")
            status.update(label="‚úÖ Contexto relevante selecionado!", state="complete")
        
        with st.status("3Ô∏è‚É£ Gerando resposta final...", expanded=True) as status:
            final_answer = get_final_unified_answer(query, context)
            status.update(label="‚úÖ An√°lise conclu√≠da!", state="complete")

    return final_answer, all_sources_structured

def main():
    st.title("ü§ñ Agente de An√°lise de Planos de Incentivo (ILP)")
    st.markdown("---")

    embedding_model, cross_encoder_model, artifacts, summary_data, setores_disponiveis, controles_disponiveis = setup_and_load_data()
        
    if not summary_data or not artifacts:
        st.error("‚ùå Falha cr√≠tica no carregamento dos dados. O app n√£o pode continuar.")
        st.stop()
    
    engine = AnalyticalEngine(summary_data, DICIONARIO_UNIFICADO_HIERARQUICO) 
    
    try:
        from catalog_data import company_catalog_rich 
    except ImportError:
        company_catalog_rich = [] 
    
    st.session_state.company_catalog_rich = company_catalog_rich

   
    from tools import _create_company_lookup_map
    st.session_state.company_lookup_map = _create_company_lookup_map(company_catalog_rich)


    with st.sidebar:
        st.header("üìä Informa√ß√µes do Sistema")
        st.metric("Categorias de Documentos (RAG)", len(artifacts))
        st.metric("Empresas no Resumo", len(summary_data))
                # --- MODIFICA√á√ÉO 2: Usar as listas din√¢micas ---
        st.header("‚öôÔ∏è Filtros da An√°lise")
        st.caption("Filtre a base de dados antes de fazer sua pergunta.")
        
        selected_setor = st.selectbox(
            label="Filtrar por Setor",
            options=setores_disponiveis, # Usa a lista din√¢mica
            index=0
        )
        
        selected_controle = st.selectbox(
            label="Filtrar por Controle Acion√°rio",
            options=controles_disponiveis, # Usa a lista din√¢mica
            index=0
        )
        st.markdown("---") 
        with st.expander("Empresas com dados no resumo"):
            st.dataframe(pd.DataFrame(sorted(list(summary_data.keys())), columns=["Empresa"]), use_container_width=True, hide_index=True)
        st.success("‚úÖ Sistema pronto para an√°lise")
        st.info(f"Embedding Model: `{MODEL_NAME}`")
        st.info(f"Generative Model: `{GEMINI_MODEL}`")
    
    st.header("üí¨ Fa√ßa sua pergunta")
    
    # Em app.py, localize o bloco `with st.expander(...)` e substitua seu conte√∫do por este:

    with st.expander("‚ÑπÔ∏è **Guia do Usu√°rio: Como Extrair o M√°ximo do Agente**", expanded=False): # `expanded=False` √© uma boa pr√°tica para n√£o poluir a tela inicial
        st.markdown("""
        Este agente foi projetado para atuar como um consultor especialista em Planos de Incentivo de Longo Prazo (ILP), analisando uma base de dados de documentos p√∫blicos da CVM. Para obter os melhores resultados, formule perguntas que explorem suas principais capacidades.
        """)

        st.subheader("1. Perguntas de Listagem (Quem tem?) üéØ")
        st.info("""
        Use estas perguntas para identificar e listar empresas que adotam uma pr√°tica espec√≠fica. Ideal para mapeamento de mercado.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Liste as empresas que pagam dividendos ou JCP durante o per√≠odo de car√™ncia (vesting).
        - Quais companhias possuem cl√°usulas de Malus ou Clawback?
        - Gere uma lista de empresas que oferecem planos com contrapartida do empregador (Matching/Coinvestimento).
        - Quais organiza√ß√µes mencionam explicitamente o Comit√™ de Remunera√ß√£o como √≥rg√£o aprovador dos planos?""")

        st.subheader("2. An√°lise Estat√≠stica (Qual a m√©dia?) üìà")
        st.info("""
        Pergunte por m√©dias, medianas e outros dados estat√≠sticos para entender os n√∫meros por tr√°s das pr√°ticas de mercado e fazer benchmarks.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Qual o per√≠odo m√©dio de vesting (em anos) entre as empresas analisadas?
        - Qual a dilui√ß√£o m√°xima m√©dia (% do capital social) que os planos costumam aprovar?
        - Apresente as estat√≠sticas do desconto no pre√ßo de exerc√≠cio (m√≠nimo, m√©dia, m√°ximo).
        - Qual o prazo de lock-up (restri√ß√£o de venda) mais comum ap√≥s o vesting das a√ß√µes?""")

        st.subheader("3. Padr√µes de Mercado (Como √© o normal?) üó∫Ô∏è")
        st.info("""
        Fa√ßa perguntas abertas para que o agente analise diversos planos e descreva os padr√µes e as abordagens mais comuns para um determinado t√≥pico.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Analise os modelos t√≠picos de planos de A√ß√µes Restritas (RSU), o tipo mais comum no mercado.
        - Al√©m do TSR, quais s√£o as metas de performance (ESG, Financeiras) mais utilizadas pelas empresas?
        - Descreva os padr√µes de tratamento para condi√ß√µes de sa√≠da (Good Leaver vs. Bad Leaver) nos planos.
        - Quais as abordagens mais comuns para o tratamento de dividendos em a√ß√µes ainda n√£o investidas?""")

        st.subheader("4. An√°lise Profunda e Comparativa (Me explique em detalhes) üß†")
        st.info("""
        Use o poder do RAG para pedir an√°lises detalhadas sobre uma ou mais empresas, comparando regras e estruturas espec√≠ficas.
        """)
        st.markdown("**Exemplos:**")
        st.code("""- Como o plano da Vale trata a acelera√ß√£o de vesting em caso de mudan√ßa de controle?
        - Compare as cl√°usulas de Malus/Clawback da Vale com as do Ita√∫.
        - Descreva em detalhes o plano de Op√ß√µes de Compra da Localiza, incluindo prazos, condi√ß√µes e forma de liquida√ß√£o.
        - Descreva o Item 8.4 da M.dias Braco.
        - Quais as diferen√ßas na elegibilidade de participantes entre os planos da Magazine Luiza e da Lojas Renner?""")


        st.subheader("‚ùó Conhecendo as Limita√ß√µes")
        st.warning("""
        - **Fonte dos Dados:** Minha an√°lise se baseia em documentos p√∫blicos da CVM com data de corte 31/07/2025. N√£o tenho acesso a informa√ß√µes em tempo real ou privadas.
        - **Identifica√ß√£o de Nomes:** Para an√°lises profundas, preciso que o nome da empresa seja claro e reconhec√≠vel. Se o nome for amb√≠guo ou n√£o estiver na minha base, posso n√£o encontrar os detalhes.
        - **Escopo:** Sou altamente especializado em Incentivos de Longo Prazo. Perguntas fora deste dom√≠nio podem n√£o ter respostas adequadas.
        """)

    user_query = st.text_area("Sua pergunta:", height=100, placeholder="Ex: Quais s√£o os modelos t√≠picos de vesting? ou Como funciona o plano da Vale?")
    
    if st.button("üîç Analisar", type="primary", use_container_width=True):
        if not user_query.strip():
            st.warning("‚ö†Ô∏è Por favor, digite uma pergunta.")
            st.stop()
        active_filters = {}
        if selected_setor != "Todos":
            active_filters['setor'] = selected_setor.lower()
        if selected_controle != "Todos":
            # A chave 'controle_acionario' deve ser exatamente como nos metadados dos chunks.
            active_filters['controle_acionario'] = selected_controle.lower()
        if active_filters:
            # Formata o dicion√°rio para uma exibi√ß√£o amig√°vel.
            filter_text_parts = []
            if 'setor' in active_filters:
                filter_text_parts.append(f"**Setor**: {active_filters['setor'].capitalize()}")
            if 'controle_acionario' in active_filters:
                filter_text_parts.append(f"**Controle**: {active_filters['controle_acionario'].capitalize()}")

            filter_text = " e ".join(filter_text_parts)
            st.info(f"üîé An√°lise sendo executada com os seguintes filtros: {filter_text}")

        st.markdown("---")
        st.subheader("üìã Resultado da An√°lise")
                # --- IN√çCIO DA NOVA L√ìGICA DE ROTEAMENTO H√çBRIDO ---
        
        intent = None
        query_lower = user_query.lower()
        
        # 1. Camada de Regras: Verifica palavras-chave quantitativas √≥bvias primeiro.
        quantitative_keywords = [
            'liste', 'quais empresas', 'quais companhias', 'quantas', 'm√©dia', 
            'mediana', 'estat√≠sticas', 'mais comuns', 'preval√™ncia', 'contagem'
        ]
        
        if any(keyword in query_lower for keyword in quantitative_keywords):
            intent = "quantitativa"
            logger.info("Inten√ß√£o 'quantitativa' detectada por regras de palavras-chave.")
        
        # 2. Camada de LLM: Se nenhuma regra correspondeu, consulta o LLM.
        if intent is None:
            with st.spinner("Analisando a inten√ß√£o da sua pergunta..."):
                intent = get_query_intent_with_llm(user_query)

        # --- FIM DA NOVA L√ìGICA DE ROTEAMENTO H√çBRIDO ---

        if intent == "quantitativa":
            query_lower = user_query.lower()
            listing_keywords = ["quais empresas", "liste as empresas", "quais companhias"]
            thematic_keywords = ["modelos t√≠picos", "padr√µes comuns", "analise os planos", "formas mais comuns"]
                # --- IN√çCIO DA L√ìGICA CORRIGIDA E FINAL ---
            
            # 1. Usa a nova fun√ß√£o para criar o mapa hier√°rquico
            alias_map = create_hierarchical_alias_map(DICIONARIO_UNIFICADO_HIERARQUICO)
            found_topics = set()
            
            # 2. Itera nos aliases para encontrar os t√≥picos mencionados na query
            for alias in sorted(alias_map.keys(), key=len, reverse=True):
                if re.search(r'\b' + re.escape(alias) + r'\b', query_lower):
                    full_path = alias_map[alias]
                    topic_leaf = full_path.split(',')[-1].replace('_', ' ')
                    found_topics.add(topic_leaf)
            
            topics_to_search = list(found_topics)
            # Remove palavras-chave gen√©ricas da lista de t√≥picos
            topics_to_search = [t for t in topics_to_search if t.lower() not in listing_keywords and t.lower() not in thematic_keywords]

            # --- FIM DA L√ìGICA CORRIGIDA E FINAL ---

            # Rota 1: An√°lise Tem√°tica
            if any(keyword in query_lower for keyword in thematic_keywords) and topics_to_search:
                primary_topic = topics_to_search[0]
                with st.spinner(f"Iniciando an√°lise tem√°tica... Este processo √© detalhado e pode levar alguns minutos."):
                    st.write(f"**T√≥pico identificado para an√°lise tem√°tica:** `{topics_to_search}`")
                    final_report = analyze_topic_thematically(
                        topic=topics_to_search, query=user_query, artifacts=artifacts, model=embedding_model, kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                        execute_dynamic_plan_func=execute_dynamic_plan, get_final_unified_answer_func=get_final_unified_answer,filters=active_filters,
                        company_catalog_rich=st.session_state.company_catalog_rich, company_lookup_map=st.session_state.company_lookup_map,
                    )
                    st.markdown(final_report)

            # Rota 2: Listagem de Empresas
            elif any(keyword in query_lower for keyword in listing_keywords) and topics_to_search:
                with st.spinner(f"Usando ferramentas para encontrar empresas..."):
                    st.write(f"**T√≥picos identificados para busca:** `{', '.join(topics_to_search)}`")
        
                    all_found_companies = set()
        
                    # CORRE√á√ÉO: Itera sobre a lista e chama a ferramenta para CADA t√≥pico.
                    for topic_item in topics_to_search:
                        companies = find_companies_by_topic(
                            topic=topic_item,  # Passa um √∫nico t√≥pico (string)
                            artifacts=artifacts, 
                            model=embedding_model, 
                            kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                            filters=active_filters
                        )
                        all_found_companies.update(companies)

                    if all_found_companies:
                        sorted_companies = sorted(list(all_found_companies))
                        final_answer = f"#### Foram encontradas {len(sorted_companies)} empresas para os t√≥picos relacionados:\n"
                        final_answer += "\n".join([f"- {company}" for company in sorted_companies])
                    else:
                        final_answer = "Nenhuma empresa encontrada nos documentos para os t√≥picos identificados."
                
                st.markdown(final_answer)
                     # --- IN√çCIO DA NOVA ROTA 2.5 ---
            # Rota 2.5: Listagem de Empresas APENAS POR FILTRO
            elif any(keyword in query_lower for keyword in listing_keywords) and active_filters and not topics_to_search:
                with st.spinner("Listando empresas com base nos filtros selecionados..."):
                    st.write("Nenhum t√≥pico t√©cnico identificado. Listando todas as empresas que correspondem aos filtros.")
                    
                    companies_from_filter = set()
                    # Itera em todos os documentos para encontrar empresas que correspondem ao filtro
                    for artifact_data in artifacts.values():
                        chunk_map = artifact_data.get('chunks', {}).get('map', [])
                        for metadata in chunk_map:
                            # Verifica se o metadado da empresa corresponde aos filtros ativos
                            setor_match = (not active_filters.get('setor') or 
                                           metadata.get('setor', '').lower() == active_filters['setor'])
                            controle_match = (not active_filters.get('controle_acionario') or 
                                              metadata.get('controle_acionario', '').lower() == active_filters['controle_acionario'])
                            
                            if setor_match and controle_match:
                                company_name = metadata.get('company_name')
                                if company_name:
                                    companies_from_filter.add(company_name)
                    
                    if companies_from_filter:
                        sorted_companies = sorted(list(companies_from_filter))
                        final_answer = f"#### Foram encontradas {len(sorted_companies)} empresas para os filtros selecionados:\n"
                        final_answer += "\n".join([f"- {company}" for company in sorted_companies])
                    else:
                        final_answer = "Nenhuma empresa foi encontrada para a combina√ß√£o de filtros selecionada."
                    
                    st.markdown(final_answer)

            # Rota 3: Fallback para o AnalyticalEngine
            else:
                st.info("Inten√ß√£o quantitativa detectada. Usando o motor de an√°lise r√°pida...")
                with st.spinner("Executando an√°lise quantitativa r√°pida..."):
                    report_text, data_result = engine.answer_query(user_query, filters=active_filters)
                    if report_text: st.markdown(report_text)
                    if data_result is not None:
                        if isinstance(data_result, pd.DataFrame):
                            if not data_result.empty: st.dataframe(data_result, use_container_width=True, hide_index=True)
                        elif isinstance(data_result, dict):
                            for df_name, df_content in data_result.items():
                                if df_content is not None and not df_content.empty:
                                    st.markdown(f"#### {df_name}")
                                    st.dataframe(df_content, use_container_width=True, hide_index=True)
                    else: 
                        st.info("Nenhuma an√°lise tabular foi gerada para a sua pergunta ou dados insuficientes.")
        
        else: # intent == 'qualitativa'
            final_answer, sources = handle_rag_query(
                user_query, 
                artifacts, 
                embedding_model, 
                cross_encoder_model, 
                kb=DICIONARIO_UNIFICADO_HIERARQUICO,
                company_catalog_rich=st.session_state.company_catalog_rich, 
                company_lookup_map=st.session_state.company_lookup_map, 
                summary_data=summary_data,
                filters=active_filters
            )
            st.markdown(final_answer)
            
            if sources:
                with st.expander(f"üìö Documentos consultados ({len(sources)})", expanded=True):
                    st.caption("Nota: Links diretos para a CVM podem falhar. Use a busca no portal com o protocolo como plano B.")
        
        # --- BLOCO CORRIGIDO ---
                    for src in sorted(sources, key=lambda x: x.get('company_name', '')):
                        company_name = src.get('company_name', 'N/A')
                        doc_type_raw = src.get('doc_type', '')
                        url = src.get('source_url', '')

                        if doc_type_raw == 'outros_documentos':
                            display_doc_type = 'Plano de Remunera√ß√£o'
                        else:
                            display_doc_type = doc_type_raw.replace('_', ' ')
            
                        display_text = f"{company_name} - {display_doc_type}"
            
                        # A l√≥gica de exibi√ß√£o agora est√° corretamente separada por tipo de documento
                        if "frmExibirArquivoIPEExterno" in url:
                            # O protocolo S√ì √© definido e usado dentro deste bloco
                            protocolo_match = re.search(r'NumeroProtocoloEntrega=(\d+)', url)
                            protocolo = protocolo_match.group(1) if protocolo_match else "N/A"
                            st.markdown(f"**{display_text}** (Protocolo: **{protocolo}**)")
                            st.markdown(f"‚Ü≥ [Link Direto para Plano de ILP]({url}) ", unsafe_allow_html=True)
            
                        elif "frmExibirArquivoFRE" in url:
                            # Este bloco n√£o usa a vari√°vel 'protocolo'
                            st.markdown(f"**{display_text}**")
                            st.markdown(f"‚Ü≥ [Link Direto para Formul√°rio de Refer√™ncia]({url})", unsafe_allow_html=True)
            
                        else:
                            # Este bloco tamb√©m n√£o usa a vari√°vel 'protocolo'
                            st.markdown(f"**{display_text}**: [Link]({url})")


if __name__ == "__main__":
    main()
